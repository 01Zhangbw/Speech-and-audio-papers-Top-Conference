# Speech and audio papers@Top Conference (Update Regularly)

Hi there! If you think this program is useful, welcome to star‚≠ê. If you want to add some, don't hesitate to PRüëÜ or emailüìß me(zhangbw0102@gmail.com)

üëè **Feel free to collaborate and contribute to this GitHub repo.**

üî• NEW UPDATE: ~~31 Jan, 2025. Êñ∞Âπ¥Âø´‰πêÔºÅ~~ 16 May, 2025

üéâ [01/23/2025] UPDATE ***ICLR 2025*** conference papers successfully!

üéâ [01/23/2025] UPDATE ***ICLR 2024*** conference papers successfully!

üéâ [01/29/2025] UPDATE ***ICML 2024*** conference papers successfully!

üéâ [01/29/2025] UPDATE ***NeurIPS 2024*** conference papers successfully!

üéâ [01/30/2025] UPDATE ***ICML 2023*** conference papers successfully!

üéâ [01/30/2025] UPDATE ***NeurIPS 2023*** conference papers successfully!

üéâ [01/30/2025] UPDATE ***ACMMM 2024*** conference papers successfully!

üéâ [01/30/2025] UPDATE ***ICLR 2023*** conference papers successfully!

üéâ [01/30/2025] UPDATE ***AAAI 2024*** conference papers successfully!

üéâ [01/31/2025] UPDATE ***ACL 2024*** conference papers successfully!

üéâ [01/31/2025] UPDATE ***EMNLP 2024*** conference papers successfully!

üéâ [03/24/2025] UPDATE ***NAACL 2025*** conference papers successfully!

üéâ [04/22/2025] UPDATE ***AAAI 2025*** conference papers successfully!

üéâ [04/22/2025] UPDATE ***IJCAI 2024*** conference papers successfully!

üéâ [05/16/2025] UPDATE ***ICML 2025*** conference papers successfully!

* [Speech and audio papers@Top Conference](#speech-and-audio-paperstop-conference)
  * [ICLR'25](#ICLR25)
    * [Speech](#Speech)
    * [Audio](#Audio)
    * [Summary](#Summary)
  * [ICLR'24](#ICLR24)
    * [Speech](#Speech-2)
    * [Audio](#Audio-2)
    * [Summary](#Summary-2)
  * [ICML'24](#ICML24)
    * [Speech](#Speech-3)
    * [Audio](#Audio-3)
  * [NeurIPS'24](#NeurIPS24)
    * [Speech](#Speech-4)
    * [Audio](#Audio-4)
  * [ICML'23](#ICML23)
    * [Speech](#Speech-5)
    * [Audio](#Audio-5)
  * [NeurIPS'23](#NeurIPS23)
    * [Speech](#Speech-6)
    * [Audio](#Audio-6)
  * [ACMMM'24](#ACMMM24)
    * [Speech](#Speech-7)
    * [Audio](#Audio-7)
  * [ICLR'23](#ICLR23)
    * [Speech](#Speech-8)
    * [Audio](#Audio-8)
  * [AAAI'24](#AAAI24)
    * [Speech](#Speech-9)
    * [Audio](#Audio-9)
  * [ACL'24](#ACL24)
    * [Speech](#Speech-10)
    * [Audio](#Audio-10)
  * [EMNLP'24](#EMNLP24)
    * [Speech](#Speech-11)
    * [Audio](#Audio-11)
  * [NAACL'25](#NAACL25)
    * [Speech](#Speech-12)
    * [Audio](#Audio-12)
  * [AAAI'25](#AAAI25)
    * [Speech](#Speech-13)
    * [Audio](#Audio-13)
  * [IJCAI'24](#IJCAI24)
    * [Speech](#Speech-14)
    * [Audio](#Audio-14)
  * [ICML'25](#ICML25)
    * [Speech](#Speech-15)
    * [Audio](#Audio-15)
  * [Useful Survey & Awesome Link](#useful-survey--awesome-link)
  * [Citation](#citation)
  * [License](#license)

## ICLR'25

ICLR'25 total submission: 11672; accepted: 3706 (31.75%)

### Speech

It includes the papers on speech (rate is good or middle, often more than 5), not limited to accepted or not.

Total speech papers@ICLR25 number is **100+**; We select **49** papers. 

**re** denotes rejected. **con** denotes conditionalonethicsreview. The numbers like 5668 denotes the detailed rate is 5,6,6,8. 

| Paper                                                        | Status                                      | Average rate |
| ------------------------------------------------------------ | ------------------------------------------- | ------------ |
| [TANGO: Co-Speech Gesture Video Reenactment with Hierarchical Audio Motion Embedding and Diffusion Interpolation](https://openreview.net/forum?id=LbEWwJOufy) | con                                         | 8.50         |
| [Co$^{\mathbf{3}}$Gesture: Towards Coherent Concurrent Co-speech 3D Gesture Generation with Interactive Diffusion](https://openreview.net/forum?id=VaowElpVzd) |                                             | 7.50         |
| [Scaling Transformers for Low-Bitrate High-Quality Speech Coding](https://openreview.net/forum?id=4YpMrGfldX) |                                             | 7.00         |
| [Context-aware Dynamic Pruning for Speech Foundation Models](https://openreview.net/forum?id=u2QdCiOgwA) |                                             | 7.00         |
| [ Scaling Speech-Text Pre-training with Synthetic Interleaved Data](https://openreview.net/forum?id=3tukjsVyrE) | con                                         | 7.00         |
| [CR-CTC: Consistency regularization on CTC for improved speech recognition](https://openreview.net/forum?id=CIs9x2ZRgh) |                                             | 6.75         |
| [Sylber: Syllabic Embedding Representation of Speech from Raw Audio](https://openreview.net/forum?id=FyMjfDQ9RO) |                                             | 6.75         |
| [Three-in-One: Fast and Accurate Transducer for Hybrid-Autoregressive Speech Recognition](https://openreview.net/forum?id=LrmPGtnros) |                                             | 6.75         |
| [Multi-Task Corrupted Prediction for Learning Robust Audio-Visual Speech Representation](https://openreview.net/forum?id=WEQL5ksDnB) |                                             | 6.75         |
| [Joint Fine-tuning and Conversion of Pretrained Speech and Language Models towards Linear Complexity](https://openreview.net/forum?id=90Db4RUBc7) |                                             | 6.75         |
| [Audio Large Language Models Can Be Descriptive Speech Quality Evaluators](https://openreview.net/forum?id=U42TkrEDzb) |                                             | 6.75         |
| [ Continuous Autoregressive Modeling with Stochastic Monotonic Alignment for Speech Synthesis](https://openreview.net/forum?id=cuFzE8Jlvb) |                                             | 6.67         |
| [EcoFace: Audio-Visual Emotional Co-Disentanglement Speech-Driven 3D Talking Face Generation](https://openreview.net/forum?id=iDcWYtYUwX) |                                             | 6.50         |
| [LLaMA-Omni: Seamless Speech Interaction with Large Language Models](https://openreview.net/forum?id=PYmrUQmMEw) |                                             | 6.50         |
| [Objective Soups: Multilingual Multi-Task Acoustic Modeling for Automatic Speech Recognition](https://openreview.net/forum?id=gW4bdLwypB) | **not accepted but rate is good**           | 6.50         |
| [ SyllableLM: Learning Coarse Semantic Units for Speech Language Models](https://openreview.net/forum?id=dGSOn7sdWg) |                                             | 6.50         |
| [Improving Semantic Understanding in Speech Language Models via Brain-tuning](https://openreview.net/forum?id=KL8Sm4xRn7) |                                             | 6.50         |
| [ SonicSim: A customizable simulation platform for speech processing in moving sound source scenarios](https://openreview.net/forum?id=Hx2ADQLi8M) |                                             | 6.50         |
| [Bridging the Data Provenance Gap Across Text, Speech, and Video](https://openreview.net/forum?id=G5DziesYxL) |                                             | 6.50         |
| [HALL-E: Hierarchical Neural Codec Language Model for Minute-Long Zero-Shot Text-to-Speech Synthesis](https://openreview.net/forum?id=868masI331) |                                             | 6.40         |
| [DiTTo-TTS: Diffusion Transformers for Scalable Text-to-Speech without Domain-Specific Factors](https://openreview.net/forum?id=hQvX9MBowC) |                                             | 6.25         |
| [T2V2: A Unified Non-Autoregressive Model for Speech Recognition and Synthesis via Multitask Learning](https://openreview.net/forum?id=TtKN1TpvUu) |                                             | 6.25         |
| [ VLAS: Vision-Language-Action Model with Speech Instructions for Customized Robot Manipulation](https://openreview.net/forum?id=K4FAFNRpko) |                                             | 6.25         |
| [ GenSE: Generative Speech Enhancement via Language Models using Hierarchical Modeling](https://openreview.net/forum?id=1p6xFLBU4J) |                                             | 6.00         |
| [UniWav: Towards Unified Pre-training for Speech Representation Learning and Generation](https://openreview.net/forum?id=yj9lLwMjnE) |                                             | 6.00         |
| [FIRING-Net: A filtered feature recycling network for speech enhancement](https://openreview.net/forum?id=TJp3LnQgSX) |                                             | 6.00         |
| [TIGER: Time-frequency Interleaved Gain Extraction and Reconstruction for Efficient Speech Separation](https://openreview.net/forum?id=rzx3vcvlzj) |                                             | 5.83         |
| [ NIRANTAR: Continual Learning with New Languages and Domains on Real-world Speech Data](https://openreview.net/forum?id=Exnt2DcdKD) | 55568, rejected                             | 5.80         |
| [Sparse Alignment Enhanced Latent Diffusion Transformer for Zero-Shot Speech Synthesis](https://openreview.net/forum?id=o362EkNU2z) | 5666, rejected                              | 5.75         |
| [VChangeCodec: A High-efficiency Neural Speech Codec with Built-in Voice Changer for Real-time Communication](https://openreview.net/forum?id=qDSfOQBrOD) | 5666, rejected                              | 5.75         |
| [Speech Robust Bench: A Robustness Benchmark For Speech Recognition](https://openreview.net/forum?id=D0LuQNZfEl) | **5666,accepted**                           | 5.75         |
| [OTTC: A differentiable alignment approach to automatic speech recognition](https://openreview.net/forum?id=EMpvfnzQqD) | 368, rejected                               | 5.68         |
| [SpeechFake: A Large-Scale Multilingual Speech Deepfake Dataset Toward Cutting-Edge Speech Generation Methods](https://openreview.net/forum?id=GpUO6qYNQG) | 566, rejected                               | 5.67         |
| [Realistic-Gesture: Co-Speech Gesture Video Generation through Semantic-aware Gesture Representation](https://openreview.net/forum?id=EXsiGFkwV6) | 35668, rejected                             | 5.60         |
| [ A$^2$-Flow: Alignment-Aware Pre-training for Speech Synthesis with Flow Matching](https://openreview.net/forum?id=e2p1BWR3vq) | 3568, rejected                              | 5.50         |
| [Representing speech through autoregressive prediction of cochlear tokens](https://openreview.net/forum?id=TQdg1X6eqm) | 5566, rejected                              | 5.50         |
| [F5-TTS: A Fairytaler that Fakes Fluent and Faithful Speech with Flow Matching](https://openreview.net/forum?id=JiX2DuTkeU) | **3568, rejected, but have big influence!** | 5.50         |
| [ASROB: Measuring Automatic Speech Recognition from One Book](https://openreview.net/forum?id=sjvz40tazX) | 3568, rejected,                             | 5.50         |
| [SSR: Alignment-Aware Modality Connector for Speech Language Models](https://openreview.net/forum?id=tZDhrhUOcs) | 3568, rejected,                             | 5.50         |
| [A Variational Approach for Generative Speech Language Modeling](https://openreview.net/forum?id=IQN4XnIEhL) | 3568, re                                    | 5.50         |
| [SPARQ: Outlier-free SpeechLM with Fast Adaptation and Robust Quantization](https://openreview.net/forum?id=Z2uhdwOrn0) | 5566,re                                     | 5.50         |
| [Vevo: Controllable Zero-Shot Voice Imitation with Self-Supervised Disentanglement](https://openreview.net/forum?id=anQDiQZhDP) | **3568, accepted**                          | 5.50         |
| [ Enhancing Zero-shot Text-to-Speech Synthesis with Human Feedback](https://openreview.net/forum?id=bAdSmSR10C) | 3568,re                                     | 5.50         |
| [ Time-Accurate Speech Rich Transcription with Non-Fluencies](https://openreview.net/forum?id=gHPUXP51L0) | 5566 withdraw                               | 5.50         |
| [dMel: Speech Tokenization Made Simple](https://openreview.net/forum?id=BomQa84efw) | 35568 re                                    | 5.40         |
| [ Orator: LLM-Guided Multi-Shot Speech Video Generation](https://openreview.net/forum?id=Bz6eAiOjrI) | 35568 re                                    | 5.40         |
| [MaskGCT: Zero-Shot Text-to-Speech with Masked Generative Codec Transformer](https://openreview.net/forum?id=ExuBFYtCQU) | **3666, accepted, have big influence!**     | 5.25         |
| [Strategic Filtering for Content Moderation: Free Speech or Free of Distortion?](https://openreview.net/forum?id=lqid8idmeG) | 5556, re                                    | 5.25         |
| [ControlSpeech: Towards Simultaneous Zero-shot Speaker Cloning and Zero-shot Language Style Control](https://openreview.net/forum?id=zAogQOIphH) | 35558, withdraw                             | 5.20         |
| [VALL-E 2: Neural Codec Language Models are Human Parity Zero-Shot Text to Speech Synthesizers](https://openreview.net/forum?id=0bcRCD7YUx) | 3368, re                                    | 5.00         |
|                                                              |                                             |              |

### Audio

It includes the papers on speech (rate is good or middle, often more than 5), not limited to accepted or not.

Total speech papers@ICLR25 number is **70+**; We select  **36** papers.

| Paper                                                        | status              | average rate |
| ------------------------------------------------------------ | ------------------- | ------------ |
| [Loopy: Taming Audio-Driven Portrait Avatar with Long-Term Motion Dependency](https://openreview.net/forum?id=weM4YBicIP) | con                 | 8.00         |
| [CyberHost: A One-stage Diffusion Framework for Audio-driven Talking Body Generation](https://openreview.net/forum?id=vaEPihQsAA) |                     | 7.60         |
| [$\texttt{BirdSet}$: A Large-Scale Dataset for Audio Classification in Avian Bioacoustics](https://openreview.net/forum?id=dRXxFEY8ZE) |                     | 7.50         |
| [ADIFF: Explaining audio difference using natural language](https://openreview.net/forum?id=l4fMj4Vnly) |                     | 7.50         |
| [ Both Ears Wide Open: Towards Language-Driven Spatial Audio Generation](https://openreview.net/forum?id=qPx3i9sMxv) |                     | 7.50         |
| [FlowDec: A flow-based full-band general audio codec with high perceptual quality](https://openreview.net/forum?id=uxDFlPGRLX) |                     | 7.00         |
| [ I Can Hear You: Selective Robust Training for Deepfake Audio Detection](https://openreview.net/forum?id=2GcR9bO620) | con                 | 7.00         |
| [ SSLAM: Enhancing Self-Supervised Models with Audio Mixtures for Polyphonic Soundscapes](https://openreview.net/forum?id=odU59TxdiB) |                     | 7.00         |
| [RFWave: Multi-band Rectified Flow for Audio Waveform Reconstruction](https://openreview.net/forum?id=gRmWtOnTLK) |                     | 6.80         |
| [Enhancing Deception Detection with Cognitive Load Features: An Audio-Visual Approach](https://openreview.net/forum?id=WNZNsyzcaB) |                     | 6.75         |
| [ Sylber: Syllabic Embedding Representation of Speech from Raw Audio](https://openreview.net/forum?id=FyMjfDQ9RO) |                     | 6.75         |
| [Synthio: Augmenting Small-Scale Audio Classification Datasets with Synthetic Data](https://openreview.net/forum?id=bR1J7SpzrD) |                     | 6.75         |
| [ Multi-Task Corrupted Prediction for Learning Robust Audio-Visual Speech Representation](https://openreview.net/forum?id=WEQL5ksDnB) |                     | 6.75         |
| [ Audio Large Language Models Can Be Descriptive Speech Quality Evaluators](https://openreview.net/forum?id=U42TkrEDzb) |                     | 6.75         |
| [ Fugatto 1: Foundational Generative Audio Transformer Opus 1](https://openreview.net/forum?id=B2Fqu7Y2cd) |                     | 6.75         |
| [WavTokenizer: an Efficient Acoustic Discrete Codec Tokenizer for Audio Language Modeling](https://openreview.net/forum?id=yBlVlS2Fd9) | 35810               | 6.50         |
| [EcoFace: Audio-Visual Emotional Co-Disentanglement Speech-Driven 3D Talking Face Generation](https://openreview.net/forum?id=iDcWYtYUwX) |                     | 6.50         |
| [ViSAGe: Video-to-Spatial Audio Generation](https://openreview.net/forum?id=8bF1Vaj9tm) |                     | 6.40         |
| [Aligned Better, Listen Better For Audio-Visual Large Language Models](https://openreview.net/forum?id=1SYUKPeM12) |                     | 6.25         |
| [Contrastive Learning from Synthetic Audio Doppelg√§ngers](https://openreview.net/forum?id=XRtyVELwr6) |                     | 6.25         |
| [AVHBench: A Cross-Modal Hallucination Benchmark for Audio-Visual Large Language Models](https://openreview.net/forum?id=jTEKTdI3K9) |                     | 6.20         |
| [ Elucidating the Design Space of Text-to-Audio Models](https://openreview.net/forum?id=xmgvF0sLIn) | 5568, re            | 6.00         |
| [Hallo2: Long-Duration and High-Resolution Audio-Driven Portrait Image Animation](https://openreview.net/forum?id=rkzabmWl5k) |                     | 6.00         |
| [Discriminator-Guided Cooperative Diffusion for Joint Audio and Video Generation](https://openreview.net/forum?id=agbiPPuSeQ) |                     | 6.00         |
| [ Rethinking Audio-Visual Adversarial Vulnerability from Temporal and Modality Perspectives](https://openreview.net/forum?id=ePJrZLIqpV) |                     | 6.00         |
| [Talking Turns: Benchmarking Audio Foundation Models on Turn-Taking Dynamics](https://openreview.net/forum?id=2e4ECh0ikn) |                     | 5.80         |
| [Active Audio Cancellation with Multi-Band Mamba Network](https://openreview.net/forum?id=LwLaFpJpfM) | 3668, re            | 5.75         |
| [The Curse of Multi-Modalities: Evaluating Hallucinations of Large Multimodal Models across Language, Visual, and Audio](https://openreview.net/forum?id=VeSsiD0DP9) | 5666, re            | 5.75         |
| [AdvWave: Stealthy Adversarial Jailbreak Attack against Large Audio-Language Models](https://openreview.net/forum?id=0BujOfTqab) | **3388, accepted**  | 5.50         |
| [ NatureLM-audio: an Audio-Language Foundation Model for Bioacoustics](https://openreview.net/forum?id=hJVdwBpWjt) | **3,5,8, accepted** | 5.33         |
| [ Taming Data and Transformers for Audio Generation](https://openreview.net/forum?id=lidVssyB7G) | 3666, re            | 5.25         |
| [ AVESFormer: Efficient Transformer Design for Real-Time Audio-Visual Segmentation](https://openreview.net/forum?id=u8SYRtXDsZ) | 5556, re            | 5.25         |
| [Segment, Associate, and Classify: Decoupled Audio-Visual Segmentation Framework](https://openreview.net/forum?id=8VnS320esG) | 5556 withdraw       | 5.25         |
| [Reverse the auditory processing pathway: Coarse-to-fine audio reconstruction from fMRI](https://openreview.net/forum?id=3JoLo0mmHH) | 3558, re            | 5.25         |
| [ Collaborative Hybrid Propagator for Temporal Misalignment in Audio-Visual Segmentation](https://openreview.net/forum?id=yqJoqtUwSI) | 35558, withdraw     | 5.20         |
| [T2A-Feedback: Improving Basic Capabilities of Text-to-Audio Generation via Fine-grained AI Feedback](https://openreview.net/forum?id=H8QvefExFf) | 3566, withdraw      | 5.00         |

### Summary

The accepted(or not) status depends on rate mainly. The rate of speech/audio track is not high, which is much less than the tracks like CV, NLP, etc. **The rebuttals are very important!!!**

## ICLR'24

### Speech

It includes the papers on speech (rate is good or middle, often more than 5), not limited to accepted or not.

Total speech papers@ICLR24 number is **50+**; We select  **20+** papers.

| Paper                                                        | status                                                       | average rate |
| ------------------------------------------------------------ | ------------------------------------------------------------ | ------------ |
| [NaturalSpeech 2: Latent Diffusion Models are Natural and Zero-Shot Speech and Singing Synthesizers](https://openreview.net/forum?id=Rc7dAwVL3v) | Spot                                                         | 8.00         |
| [ Large Language Models are Efficient Learners of Noise-Robust Speech Recognition](https://openreview.net/forum?id=ceATjGPTUD) | Spot                                                         | 8.00         |
| [ Multi-resolution HuBERT: Multi-resolution Speech Self-Supervised Learning with Masked Unit Prediction](https://openreview.net/forum?id=kUuKFW7DIF) | Spot                                                         | 8.00         |
| [Zipformer: A faster and better encoder for automatic speech recognition](https://openreview.net/forum?id=9WD9KwssyT) | Oral                                                         | 7.50         |
| [ RTFS-Net: Recurrent Time-Frequency Modelling for Efficient Audio-Visual Speech Separation](https://openreview.net/forum?id=PEuDO2EiDr) |                                                              | 7.50         |
| [Self-Supervised Speech Quality Estimation and Enhancement Using Only Clean Speech](https://openreview.net/forum?id=ale56Ya59q) |                                                              | 7.00         |
| [Spoken Question Answering and Speech Continuation Using Spectrogram-Powered LLM](https://openreview.net/forum?id=izrOLJov5y) |                                                              | 6.75         |
| [SALMONN: Towards Generic Hearing Abilities for Large Language Models](https://openreview.net/forum?id=14rn7HpKVk) |                                                              | 6.67         |
| [It's Never Too Late: Fusing Acoustic Information into Large Language Models for Automatic Speech Recognition](https://openreview.net/forum?id=QqjFHyQwtF) |                                                              | 6.60         |
| [ Mega-TTS 2: Boosting Prompting Mechanisms for Zero-Shot Speech Synthesis](https://openreview.net/forum?id=mvMI3N4AvD) |                                                              | 6.50         |
| [CLaM-TTS: Improving Neural Codec Language Model for Zero-Shot Text-to-Speech](https://openreview.net/forum?id=ofzeypWosV) |                                                              | 6.40         |
| [BLSP: Bootstrapping Language-Speech Pre-training via Behavior Alignment of Continuation Writing](https://openreview.net/forum?id=H4zAFFyoXK) | 5668, re, link: https://arxiv.org/pdf/2309.00916             | 6.25         |
| [TransFace: Unit-Based Audio-Visual Speech Synthesizer for Talking Head Translation](https://openreview.net/forum?id=71oyMJiUm2) | 5668, desk re, **accepted by ACL2024**, https://aclanthology.org/2024.findings-acl.593.pdf | 6.25         |
| [ Multilingual Visual Speech Recognition with a Single Model using Visual Speech Unit](https://openreview.net/forum?id=M8J0b9gNfG) | 56668, re,  link: https://arxiv.org/pdf/2401.09802v1         | 6.20         |
| [PromptTTS 2: Describing and Generating Voices with Text Prompt](https://openreview.net/forum?id=NsCXDyv2Bn) |                                                              | 6.00         |
| [Separate and Diffuse: Using a Pretrained Diffusion Model for Better Source Separation](https://openreview.net/forum?id=UXALv0lJZS) |                                                              | 6.00         |
| [PolyVoice: Language Models for Speech to Speech Translation](https://openreview.net/forum?id=hCrFG9cyuC) | **3588, accepted**                                           | 6.00         |
| [DiffPoseTalk: Speech-Driven Stylistic 3D Facial Animation and Head Pose Generation via Diffusion Models](https://openreview.net/forum?id=PORUmWsgBN) | 5568, re, **accepted by SIGGRAPH 2024 (Journal Track)**, https://arxiv.org/pdf/2310.00434 | 6.00         |
| [ LipVoicer: Generating Speech from Silent Videos Guided by Lip Reading](https://openreview.net/forum?id=ZZCPSC5OgD) | **5568,accepted**                                            | 6.00         |
| [ Generative Pre-training for Speech with Flow Matching](https://openreview.net/forum?id=KpoQSgxbKH) | **3668,accepted**                                            | 5.75         |
| [DiffAR: Denoising Diffusion Autoregressive Model for Raw Speech Waveform Generation](https://openreview.net/forum?id=GTk0AdOYLq) | **5666,accepted**                                            | 5.75         |
| [SpeechTokenizer: Unified Speech Tokenizer for Speech Language Models](https://openreview.net/forum?id=AF9Q8Vip84) | **3668,accepted**                                            | 5.75         |
| [SummaryMixing: A Linear-Complexity Alternative to Self-Attention for Speech Recognition and Understanding](https://openreview.net/forum?id=PoBB8n52oi) | 3568, rem **accepted by Interspeech24**, https://arxiv.org/pdf/2307.07421 | 5.75         |
| [ RepCodec: A Speech Representation Codec for Speech Tokenization](https://openreview.net/forum?id=LfDUzzQa3g) | 5566, re, **accepted by ACL-main2024**, https://arxiv.org/pdf/2309.00169 | 5.50         |
| [ A Discrete and Variational Approach to Speech Representation Learning](https://openreview.net/forum?id=rQRDt8F2Yh) | 33588, withdraw                                              | 5.40         |
| [Generative Pre-Trained Speech Language Model with Efficient Hierarchical Transformer](https://openreview.net/forum?id=TJNCnkDRkY) | 5556, re, **accepted by ACL2024**, https://arxiv.org/pdf/2406.00976 | 5.25         |

### Audio

It includes the papers on speech (rate is good or middle, often more than 5), not limited to accepted or not.

Total speech papers@ICLR24 number is **20+**; We select  **17** papers.

| Paper                                                        | status                      | average rate |
| ------------------------------------------------------------ | --------------------------- | ------------ |
| [Masked Audio Generation using a Single Non-Autoregressive Transformer](https://openreview.net/forum?id=Ny8NiVfi95) |                             | 7.33         |
| [Listen, Think, and Understand](https://openreview.net/forum?id=nBZBPXdJlC) |                             | 7.00         |
| [Revisiting Deep Audio-Text Retrieval Through the Lens of Transportation](https://openreview.net/forum?id=l60EM8md3t) |                             | 6.67         |
| [ Weakly-supervised Audio Separation via Bi-modal Semantic Similarity](https://openreview.net/forum?id=4N97bz1sP6) |                             | 6.67         |
| [CompA: Addressing the Gap in Compositional Reasoning in Audio-Language Models](https://openreview.net/forum?id=86NGO8qeWs) |                             | 6.50         |
| [Vocos: Closing the gap between time-domain and Fourier-based neural vocoders for high-quality audio synthesis](https://openreview.net/forum?id=vY9nzQmQBw) |                             | 6.00         |
| [ Lifelong Audio-video Masked Autoencoder with Forget-robust Localized Alignments](https://openreview.net/forum?id=GGPyzKsHZ1) | 55558Ôºå re                  | 5.60         |
| [ LAURAGPT: LISTEN, ATTEND, UNDERSTAND, AND REGENERATE AUDIO WITH GPT](https://openreview.net/forum?id=jDy2Djjrge) | 5566Ôºå re                   | 5.50         |
| [SoundStorm: Efficient Parallel Audio Generation](https://openreview.net/forum?id=KknWbD5j95) | 35568, re                   | 5.40         |
| [Bootstrapping Audio-Visual Segmentation by Strengthening Audio Cues](https://openreview.net/forum?id=WdWGe88RdX) | 3666, re                    | 5.25         |
| [FINE-GRAINED AUDIO-VISUAL JOINT REPRESENTATIONS FOR MULTIMODAL LARGE LANGUAGE MODELS](https://openreview.net/forum?id=wD8L86iCvD) | 3666, re                    | 5.25         |
| [ UniAudio: An Audio Foundation Model Toward Universal Audio Generation](https://openreview.net/forum?id=nhgTmx1TZJ) | 15510, re, accept by icml24 | 5.25         |
| [Masked Autoencoders with Multi-Window Local-Global Attention Are Better Audio Learners](https://openreview.net/forum?id=Q53QLftNkA) | 3666, re                    | 5.25         |
| [ SMILE: Audio-Visual Speech Recognition with Siamese Masked Interaction Learning](https://openreview.net/forum?id=74IIsh2kM6) | 5555, re                    | 5.00         |
| [Leveraging characteristics of the output distribution for identifying adversarial audio examples](https://openreview.net/forum?id=R1crLHQ4kf) | 5555, re                    | 5.00         |
| [Rethinking Audiovisual Segmentation with Semantic Quantization and Decomposition](https://openreview.net/forum?id=nuWVS4SBUu) | 5555, re                    | 5.00         |
| [ WavJourney: Compositional Audio Creation with Large Language Models](https://openreview.net/forum?id=8JCn0kmS8W) | 35566, re                   | 5.00         |

### Summary

This year, the paper's number is not so large.

## ICML'24

### Speech

| Paper                                                        | status                                             |
| ------------------------------------------------------------ | -------------------------------------------------- |
| [ELF: Encoding Speaker-Specific Latent Speech Feature for Speech Synthesis](https://icml.cc/virtual/2024/poster/33936) | [link](https://openreview.net/pdf?id=Ug1m4P4AKf)   |
| [video-SALMONN: Speech-Enhanced Audio-Visual Large Language Models](https://icml.cc/virtual/2024/poster/33117) | [link](https://openreview.net/forum?id=nYsh5GFIqX) |
| [NaturalSpeech 3: Zero-Shot Speech Synthesis with Factorized Codec and Diffusion Models](https://icml.cc/virtual/2024/poster/33552) | [link](https://openreview.net/pdf?id=dVhrnjZJad)   |
| [InstructSpeech: Following Speech Editing Instructions via Large Language Models](https://icml.cc/virtual/2024/poster/32696) | [link](https://openreview.net/pdf?id=xlWcdtCyOC)   |
| [Scaling Speech Technology to 1,000+ Languages](https://icml.cc/virtual/2024/poster/35635) | [link](https://arxiv.org/abs/2305.13516)           |
| [IIANet: An Intra- and Inter-Modality Attention Network for Audio-Visual Speech Separation](https://icml.cc/virtual/2024/poster/34541) | [link](https://openreview.net/forum?id=FM61SQzF3N) |
| [Speech Self-Supervised Learning Using Diffusion Model Synthetic Data](https://icml.cc/virtual/2024/poster/33487) | [link](https://openreview.net/pdf?id=ecnpYYHjt9)   |

### Audio

| Paper                                                        | status                                           |
| ------------------------------------------------------------ | ------------------------------------------------ |
| [Zero-Shot Unsupervised and Text-Based Audio Editing Using DDPM Inversion](https://icml.cc/virtual/2024/poster/33184) | [link](https://openreview.net/pdf?id=mCzyRdDak5) |
| [UniAudio: Towards Universal Audio Generation with Large Language Models](https://icml.cc/virtual/2024/poster/34007) | [link](https://openreview.net/pdf?id=SRmZw7nEGW) |
| [Prompt-guided Precise Audio Editing with Diffusion Models](https://icml.cc/virtual/2024/poster/33258) |                                                  |
| [Creative Text-to-Audio Generation via Synthesizer Programming](https://icml.cc/virtual/2024/poster/34961) |                                                  |
| [Fast Timing-Conditioned Latent Audio Diffusion](https://icml.cc/virtual/2024/poster/33311) |                                                  |
| [Audio Flamingo: A Novel Audio Language Model with Few-Shot Learning and Dialogue Abilities](https://icml.cc/virtual/2024/poster/33859) |                                                  |
| [Listenable Maps for Audio Classifiers](https://icml.cc/virtual/2024/poster/33268) |                                                  |
| [STELLA: Continual Audio-Video Pre-training with SpatioTemporal Localized Alignment](https://icml.cc/virtual/2024/poster/32844) |                                                  |
| [From Vision to Audio and Beyond: A Unified Model for Audio-Visual Representation and Generation](https://icml.cc/virtual/2024/poster/33302) |                                                  |
| [AND: Audio Network Dissection for Interpreting Deep Acoustic Models](https://icml.cc/virtual/2024/poster/33753) |                                                  |
| [EquiAV: Leveraging Equivariance for Audio-Visual Contrastive Learning](https://icml.cc/virtual/2024/poster/34832) |                                                  |

## NeurIPS'24

### Speech

useful link: https://nips.cc/virtual/2024/papers.html?filter=titles&search=speech

| Paper                                                        | status |
| ------------------------------------------------------------ | ------ |
| [SSDM: Scalable Speech Dysfluency Modeling](https://nips.cc/virtual/2024/poster/95746) |        |
| [SpeechForensics: Audio-Visual Speech Representation Learning for Face Forgery Detection](https://nips.cc/virtual/2024/poster/94610) |        |
| [Paralinguistics-Aware Speech-Empowered Large Language Models for Natural Conversation](https://nips.cc/virtual/2024/poster/95416) |        |
| [A Full-duplex Speech Dialogue Scheme Based On Large Language Model](https://nips.cc/virtual/2024/poster/94688) |        |
| [CA-SSLR: Condition-Aware Self-Supervised Learning Representation for Generalized Speech Processing](https://nips.cc/virtual/2024/poster/94546) |        |
| [Self-Taught Recognizer: Toward Unsupervised Adaptation for Speech Foundation Models](https://nips.cc/virtual/2024/poster/93632) |        |
| [DiffNorm: Self-Supervised Normalization for Non-autoregressive Speech-to-speech Translation](https://nips.cc/virtual/2024/poster/95019) |        |
| [SILENCE: Protecting privacy in offloaded speech understanding on resource-constrained devices](https://nips.cc/virtual/2024/poster/93343) |        |
| [FINALLY: fast and universal speech enhancement with studio-like quality](https://nips.cc/virtual/2024/poster/96882) |        |
| [SpeechAlign: Aligning Speech Generation to Human Preferences](https://nips.cc/virtual/2024/poster/95112) |        |
| [Du-IN: Discrete units-guided mask modeling for decoding speech from Intracranial Neural signals](https://nips.cc/virtual/2024/poster/93238) |        |
| [SCOREQ: Speech Quality Assessment with Contrastive Regression](https://nips.cc/virtual/2024/poster/95846) |        |
| [RealMAN: A Real-Recorded and Annotated Microphone Array Dataset for Dynamic Speech Enhancement and Localization](https://nips.cc/virtual/2024/poster/97504) |        |
| [TransVIP: Speech to Speech Translation System with Voice and Isochrony Preservation](https://nips.cc/virtual/2024/poster/94611) |        |
| [CoVoMix: Advancing Zero-Shot Speech Generation for Human-like Multi-talker Conversations](https://nips.cc/virtual/2024/poster/94904) |        |
| [Unified Speech Recognition: A Single Model for Auditory, Visual, and Audiovisual Inputs](https://nips.cc/virtual/2024/poster/93199) |        |
| [IndicVoices-R: Unlocking a Massive Multilingual Multi-speaker Speech Corpus for Scaling Indian TTS](https://nips.cc/virtual/2024/poster/97858) |        |
| [Separate and Reconstruct: Asymmetric Encoder-Decoder for Speech Separation](https://nips.cc/virtual/2024/poster/96323) |        |
| [Comprehensive Framework for Curating Speech Datasets and Evaluating ASR Systems: A Case Study for the Polish Language](https://nips.cc/virtual/2024/poster/97720) |        |

### Audio

useful link: https://nips.cc/virtual/2024/papers.html?filter=titles&search=audio

| Paper                                                        | status |
| ------------------------------------------------------------ | ------ |
| [Vocal Call Locator Benchmark (VCL'24) for localizing rodent vocalizations from multi-channel audio](https://nips.cc/virtual/2024/poster/97470) |        |
| [SLIM: Style-Linguistics Mismatch Model for Generalized Audio Deepfake Detection](https://nips.cc/virtual/2024/poster/94173) |        |
| [Tell What You Hear From What You See - Video to Audio Generation Through Text](https://nips.cc/virtual/2024/poster/93863) |        |
| [Learning Spatially-Aware Language and Audio Embeddings](https://nips.cc/virtual/2024/poster/93168) |        |
| [Lips Are Lying: Spotting the Temporal Inconsistency between Audio and Visual in Lip-Syncing DeepFakes](https://nips.cc/virtual/2024/poster/93027) |        |
| [SpeechForensics: Audio-Visual Speech Representation Learning for Face Forgery Detection](https://nips.cc/virtual/2024/poster/94610) |        |
| [Look, Listen, and Answer: Overcoming Biases for Audio-Visual Question Answering](https://nips.cc/virtual/2024/poster/93303) |        |
| [Continual Audio-Visual Sound Separation](https://nips.cc/virtual/2024/poster/95301) |        |
| [Mixtures of Experts for Audio-Visual Learning](https://nips.cc/virtual/2024/poster/95106) |        |
| [Listenable Maps for Zero-Shot Audio Classifiers](https://nips.cc/virtual/2024/poster/93828) |        |
| [Aligning Audio-Visual Joint Representations with an Agentic Workflow](https://nips.cc/virtual/2024/poster/95239) |        |
| [AV-Cloud: Spatial Audio Rendering Through Audio-Visual Cloud Splatting](https://nips.cc/virtual/2024/poster/92984) |        |
| [Frieren: Efficient Video-to-Audio Generation Network with Rectified Flow Matching](https://nips.cc/virtual/2024/poster/93527) |        |
| [An eye for an ear: zero-shot audio description leveraging an image captioner with audio-visual token distribution matching](https://nips.cc/virtual/2024/poster/94989) |        |
| [A Versatile Diffusion Transformer with Mixture of Noise Levels for Audiovisual Generation](https://nips.cc/virtual/2024/poster/94376) |        |
| [Unified Speech Recognition: A Single Model for Auditory, Visual, and Audiovisual Inputs](https://nips.cc/virtual/2024/poster/93199) |        |
| [VASA-1: Lifelike Audio-Driven Talking Faces Generated in Real Time](https://nips.cc/virtual/2024/poster/96555) |        |
| [UniAudio 1.5: Large Language Model-Driven Audio Codec is A Few-Shot Audio Task Learner](https://nips.cc/virtual/2024/poster/95454) |        |
| [AudioMarkBench: Benchmarking Robustness of Audio Watermarking](https://nips.cc/virtual/2024/poster/97471) |        |

## ICML'23

### Speech

useful link: https://icml.cc/virtual/2023/papers.html?filter=titles&search=speech

| Paper                                                        | status |
| ------------------------------------------------------------ | ------ |
| [Pre-training for Speech Translation: CTC Meets Optimal Transport](https://icml.cc/virtual/2023/poster/24195) | Oral   |
| [Efficient Self-supervised Learning with Contextualized Target Representations for Vision, Speech and Language](https://icml.cc/virtual/2023/poster/25257) | Oral   |
| [Robust Speech Recognition via Large-Scale Weak Supervision](https://icml.cc/virtual/2023/poster/24519) |        |
| [Shiftable Context: Addressing Training-Inference Context Mismatch in Simultaneous Speech Translation](https://icml.cc/virtual/2023/poster/24293) |        |
| [Self-supervised Neural Factor Analysis for Disentangling Utterance-level Speech Representations](https://icml.cc/virtual/2023/poster/24759) |        |
| [MetricGAN-OKD: Multi-Metric Optimization of MetricGAN via Online Knowledge Distillation for Speech Enhancement](https://icml.cc/virtual/2023/poster/25028) |        |
| [Mu$^2$SLAM: Multitask, Multilingual Speech and Language Models](https://icml.cc/virtual/2023/poster/24244) |        |

### Audio

useful link: https://icml.cc/virtual/2023/papers.html?filter=titles&search=audio

| Paper                                                        | Status |
| ------------------------------------------------------------ | ------ |
| [AudioLDM: Text-to-Audio Generation with Latent Diffusion Models](https://icml.cc/virtual/2023/poster/24145) |        |
| [Make-An-Audio: Text-To-Audio Generation with Prompt-Enhanced Diffusion Models](https://icml.cc/virtual/2023/poster/25060) |        |
| [A Unified Audio-Visual Learning Framework for Localization, Separation, and Recognition](https://icml.cc/virtual/2023/poster/25216) |        |
| [BEATs: Audio Pre-Training with Acoustic Tokenizers](https://icml.cc/virtual/2023/poster/24937) | Oral   |
| [Do You Remember? Overcoming Catastrophic Forgetting for Fake Audio Detection](https://icml.cc/virtual/2023/poster/24753) |        |

## NeurIPS'23

### Speech

| Paper                                                        | Status |
| ------------------------------------------------------------ | ------ |
| [High-Fidelity Audio Compression with Improved RVQGAN](https://openreview.net/forum?id=qjnl1QUnFA) | Spot   |
| [Sounding Bodies: Modeling 3D Spatial Sound of Humans Using Body Pose and Audio](https://openreview.net/forum?id=zQTi3pziFp) | Spot   |
| [How to Scale Your EMA](https://openreview.net/forum?id=DkeeXVdQyu) | Spot   |
| [Textually Pretrained Speech Language Models](https://openreview.net/forum?id=UlHueVjAKr) |        |
| [ComSL: A Composite Speech-Language Model for End-to-End Speech-to-Text Translation](https://openreview.net/forum?id=6Qx7G1xrAk) |        |
| [DASpeech: Directed Acyclic Transformer for Fast and High-quality Speech-to-Speech Translation](https://openreview.net/forum?id=JvYSSPtQyk) |        |
| [StyleTTS 2: Towards Human-Level Text-to-Speech through Style Diffusion and Adversarial Training with Large Speech Language Models](https://openreview.net/forum?id=m0RbqrUM26) |        |
| [Voicebox: Text-Guided Multilingual Universal Speech Generation at Scale](https://openreview.net/forum?id=gzCS252hCO) |        |
| [DOSE: Diffusion Dropout with Adaptive Prior for Speech Enhancement](https://openreview.net/forum?id=2C2WZfCfo9) |        |
| [P-Flow: A Fast and Data-Efficient Zero-Shot TTS through Speech Prompting](https://openreview.net/forum?id=zNA7u7wtIN) |        |
| [DinoSR: Self-Distillation and Online Clustering for Self-supervised Speech Representation Learning](https://openreview.net/forum?id=twmHKU3Ds4) |        |
| [Parts of Speech‚ÄìGrounded Subspaces in Vision-Language Models](https://openreview.net/forum?id=hLoanbRrjM) |        |
| [UNSSOR: Unsupervised Neural Speech Separation by Leveraging Over-determined Training Mixtures](https://openreview.net/forum?id=T5h69frFF7) |        |
| [Learning Repeatable Speech Embeddings Using An Intra-class Correlation Regularizer](https://openreview.net/forum?id=jCPRG3FuHV) |        |
| [Disentangling Voice and Content with Self-Supervision for Speaker Recognition](https://openreview.net/forum?id=KoFYzuwjCA) |        |
| [From Discrete Tokens to High-Fidelity Audio Using Multi-Band Diffusion](https://openreview.net/forum?id=dOanKg3jKS) |        |
| [Unified Segment-to-Segment Framework for Simultaneous Sequence Generation](https://openreview.net/forum?id=GuErIOGLie) |        |
| [Conditional Adapters: Parameter-efficient Transfer Learning with Fast Inference](https://openreview.net/forum?id=IyYyKov0Aj) |        |
| [Progressive Ensemble Distillation: Building Ensembles for Efficient Inference](https://openreview.net/forum?id=wNxyDofh74) |        |
| [LEACE: Perfect linear concept erasure in closed form](https://openreview.net/forum?id=awIpKpwTwF) |        |
| [TART: A plug-and-play Transformer module for task-agnostic reasoning](https://openreview.net/forum?id=ZXbgVm3PSt) |        |

### Audio

| Paper                                                        | Status |
| ------------------------------------------------------------ | ------ |
| [Compression with Bayesian Implicit Neural Representations](https://openreview.net/forum?id=5otj6QKUMI) | Spot   |
| [From Discrete Tokens to High-Fidelity Audio Using Multi-Band Diffusion](https://openreview.net/forum?id=dOanKg3jKS) |        |
| [Pengi: An Audio Language Model for Audio Tasks](https://openreview.net/forum?id=gJLAfO4KUq) |        |
| [AUDIT: Audio Editing by Following Instructions with Latent Diffusion Models](https://openreview.net/forum?id=EO1KuHoR0V) |        |
| [MAViL: Masked Audio-Video Learners](https://openreview.net/forum?id=OmTMaTbjac) |        |
| [Weakly-Supervised Audio-Visual Segmentation](https://openreview.net/forum?id=sUqG96QqZM) |        |
| [Disentangled Counterfactual Learning for Physical Audiovisual Commonsense Reasoning](https://openreview.net/forum?id=trHfuGQyyr) |        |
| [Diff-Foley: Synchronized Video-to-Audio Synthesis with Latent Diffusion Models](https://openreview.net/forum?id=q5FAZAIooz) |        |
| [AV-NeRF: Learning Neural Fields for Real-World Audio-Visual Scene Synthesis](https://openreview.net/forum?id=snY3FOnlQi) |        |
| [Simple and Controllable Music Generation](https://openreview.net/forum?id=jtiQ26sCJi) |        |
| [CoLLAT: On Adding Fine-grained Audio Understanding to Language Models using Token-Level Locked-Language Tuning](https://openreview.net/forum?id=2NncD8AaFK) |        |
| [VAST: A Vision-Audio-Subtitle-Text Omni-Modality Foundation Model and Dataset](https://openreview.net/forum?id=scYa9DYUAy) |        |
| [Modality-Independent Teachers Meet Weakly-Supervised Audio-Visual Event Parser](https://openreview.net/forum?id=p8gTWkFIvx) |        |
| [Dual Mean-Teacher: An Unbiased Semi-Supervised Framework for Audio-Visual Source Localization](https://openreview.net/forum?id=CFhpBJ8eZ5) |        |
| [Cross-modal Prompts: Adapting Large Pre-trained Models for Audio-Visual Downstream Tasks](https://openreview.net/forum?id=9MwidIH4ea) |        |
| [Revisit Weakly-Supervised Audio-Visual Video Parsing from the Language Perspective](https://openreview.net/forum?id=doWqIXcRlq) |        |
| [Self-Supervised Visual Acoustic Matching](https://openreview.net/forum?id=clKbFMt29V) |        |
| [Connecting Multi-modal Contrastive Representations](https://openreview.net/forum?id=IGTbT9P1ti) |        |
| [Voicebox: Text-Guided Multilingual Universal Speech Generation at Scale](https://openreview.net/forum?id=gzCS252hCO) |        |
| [Achieving Cross Modal Generalization with Multimodal Unified Representation](https://openreview.net/forum?id=t7ZowrDWVw) |        |
| [Any-to-Any Generation via Composable Diffusion](https://openreview.net/forum?id=2EDqbSCnmF) |        |
| [Efficient Neural Music Generation](https://openreview.net/forum?id=cxazQGSsQa) |        |
| [Training Transitive and Commutative Multimodal Transformers with LoReTTa](https://openreview.net/forum?id=nArzDm353Y) |        |
| [Latent Diffusion for Language Generation](https://openreview.net/forum?id=NKdtztladR) |        |
| [Block-State Transformers](https://openreview.net/forum?id=XRTxIBs2eu) |        |
| [Learning Interpretable Low-dimensional Representation via Physical Symmetry](https://openreview.net/forum?id=3iSj4l8ZGT) |        |
| [Alternating Gradient Descent and Mixture-of-Experts for Integrated Multimodal Perception](https://openreview.net/forum?id=uTlKUAm68H) |        |
| [Feature Dropout: Revisiting the Role of Augmentations in Contrastive Learning](https://openreview.net/forum?id=M7hijAPA4B) |        |
| [Language Semantic Graph Guided Data-Efficient Learning](https://openreview.net/forum?id=tUyW68cRqr) |        |

## ACMMM'24

### Speech

| Paper                                                        | Status |
| ------------------------------------------------------------ | ------ |
| [VoxInstruct: Expressive Human Instruction-to-Speech Generation with Unified Multilingual Codec Language Modelling](https://openreview.net/forum?id=hQp6qimhbb) | Oral   |
| [UniStyle: Unified Style Modeling for Speaking Style Captioning and Stylistic Speech Synthesis](https://openreview.net/forum?id=7BZ4biy975) | Oral   |
| [Boosting Speech Recognition Robustness to Modality-Distortion with Contrast-Augmented Prompts](https://openreview.net/forum?id=2bTqjmcQjT) | Oral   |
| [ArtSpeech: Adaptive Text-to-Speech Synthesis with Articulatory Representations](https://openreview.net/forum?id=nagiMHx4A3) | Oral   |
| [Self-Supervised Emotion Representation Disentanglement for Speech-Preserving Facial Expression Manipulation](https://openreview.net/forum?id=Pnaq8Sd4Ql) | Oral   |
| [Generative Expressive Conversational Speech Synthesis](https://openreview.net/forum?id=eK9ShhDqwu) |        |
| [SpeechCraft: A Fine-Grained Expressive Speech Dataset with Natural Language Description](https://openreview.net/forum?id=rjAY1DGUWC) |        |
| [CIEASR:Contextual Image-Enhanced Automatic Speech Recognition for Improved Homophone Discrimination](https://openreview.net/forum?id=v5qqd214xq) |        |
| [EGGesture: Entropy-Guided Vector Quantized Variational AutoEncoder for Co-Speech Gesture Generation](https://openreview.net/forum?id=Xmapdbf1CT) |        |
| [DEITalk: Speech-Driven 3D Facial Animation with Dynamic Emotional Intensity Modeling](https://openreview.net/forum?id=1Y3qb4987z) |        |
| [Contrastive Context-Speech Pretraining for Expressive Text-to-Speech Synthesis](https://openreview.net/forum?id=hSCBbAhSog) |        |
| [RAVSS: Robust Audio-Visual Speech Separation in Multi-Speaker Scenarios with Missing Visual Cues](https://openreview.net/forum?id=WbbfjojmjD) |        |
| [Efficient Training for Multilingual Visual Speech Recognition: Pre-training with Discretized Visual Speech Representation](https://openreview.net/forum?id=rD7guYi6jZ) |        |
| [Speech Reconstruction from Silent Lip and Tongue Articulation by Diffusion Models and Text-Guided Pseudo Target Generation](https://openreview.net/forum?id=M87zOOryOG) |        |
| [MDT-A2G: Exploring Masked Diffusion Transformers for Co-Speech Gesture Generation](https://openreview.net/forum?id=xJK53lGJP2) |        |
| [SpeechEE: A Novel Benchmark for Speech Event Extraction](https://openreview.net/forum?id=35rgn7rIn3) |        |
| [MambaGesture: Enhancing Co-Speech Gesture Generation with Mamba and Disentangled Multi-Modality Fusion](https://openreview.net/forum?id=9Jwor3Kfy2) |        |
| [Emphasizing Semantic Consistency of Salient Posture for Speech-Driven Gesture Generation](https://openreview.net/forum?id=NaUbjH7QEL) |        |
| [Enabling Synergistic Full-Body Control in Prompt-Based Co-Speech Motion Generation](https://openreview.net/forum?id=aLK06bsEgo) |        |
| [FlashSpeech: Efficient Zero-Shot Speech Synthesis](https://openreview.net/forum?id=Q5C9eNZl1m) |        |

### Audio

| Paper                                                        | Status |
| ------------------------------------------------------------ | ------ |
| [OpenAVE: Moving towards Open Set Audio-Visual Event Localization](https://openreview.net/forum?id=7gymfcw7E7) | Oral   |
| [Unveiling and Mitigating Bias in Audio Visual Segmentation](https://openreview.net/forum?id=pguhpIXhXh) | Oral   |
| [AV-Deepfake1M: A Large-Scale LLM-Driven Audio-Visual Deepfake Dataset](https://openreview.net/forum?id=YZ68Ifi4yH) | Oral   |
| [Tango 2: Aligning Diffusion-based Text-to-Audio Generative Models through Direct Preference Optimization](https://openreview.net/forum?id=7lqptq5dLG) | Oral   |
| [Towards Trustworthy MetaShopping: Studying Manipulative Audiovisual Designs in Virtual-Physical Commercial Platforms](https://openreview.net/forum?id=I4EJdRTVaf) | Oral   |
| [Open-Vocabulary Audio-Visual Semantic Segmentation](https://openreview.net/forum?id=PkW68qL47n) | Oral   |
| [Advancing Multi-grained Alignment for Contrastive Language-Audio Pre-training](https://openreview.net/forum?id=F8w9Sx3f4O) | Oral   |
| [Toward Explainable Physical Audiovisual Commonsense Reasoning](https://openreview.net/forum?id=Ls7KytN8C8) | Oral   |
| [TiVA: Time-Aligned Video-to-Audio Generation](https://openreview.net/forum?id=tIpOYtxerl) | Oral   |
| [Coarse-to-Fine Proposal Refinement Framework For Audio Temporal Forgery Detection and Localization](https://openreview.net/forum?id=vKGqzxqNM9) | Oral   |
| [SelM: Selective Mechanism based Audio-Visual Segmentation](https://openreview.net/forum?id=oiEyxnMrF0) | Oral   |
| [Dissecting Temporal Understanding in Text-to-Audio Retrieval](https://openreview.net/forum?id=HTZy9hpoYV) |        |
| [FRADE: Forgery-aware Audio-distilled Multimodal Learning for Deepfake Detection](https://openreview.net/forum?id=TWzfIkho4e) |        |
| [AMG-Embedding: a Self-Supervised Embedding Approach for Audio Identification](https://openreview.net/forum?id=H7etFJugLW) |        |
| [MMAL: Multi-Modal Analytic Learning for Exemplar-Free Audio-Visual Class Incremental Tasks](https://openreview.net/forum?id=zGoCaP7NyR) |        |
| [Utilizing Speaker Profiles for Impersonation Audio Detection](https://openreview.net/forum?id=ifKQnupnP9) |        |
| [CACE-Net: Co-guidance Attention and Contrastive Enhancement for Effective Audio-Visual Event Localization](https://openreview.net/forum?id=ue6UUvoL8B) |        |
| [CoPL:Parameter-Efficient Collaborative Prompt Learning for Audio-Visual Tasks](https://openreview.net/forum?id=adqDa13uXh) |        |
| [Time-Frequency Domain Fusion Enhancement for Audio Super-Resolution](https://openreview.net/forum?id=nrt0w3gJ3f) |        |
| [Auto-ACD: A Large-scale Dataset for Audio-Language Representation Learning](https://openreview.net/forum?id=TSuwWHORY2) |        |
| [Multi-grained Correspondence Learning of Audio-language Models for Few-shot Audio Recognition](https://openreview.net/forum?id=3BFo7AYjoa) |        |
| [Audio Deepfake Detection with Self-Supervised XLS-R and SLS Classifier](https://openreview.net/forum?id=acJMIXJg2u) |        |
| [AVHash: Joint Audio-Visual Hashing for Video Retrieval](https://openreview.net/forum?id=elDjJp4Upl) |        |
| [RAVSS: Robust Audio-Visual Speech Separation in Multi-Speaker Scenarios with Missing Visual Cues](https://openreview.net/forum?id=WbbfjojmjD) |        |
| [EchoAudio: Efficient and High-Quality Text-to-Audio Generation with Minimal Inference Steps](https://openreview.net/forum?id=OhQLdb4seO) |        |
| [Instance-Level Panoramic Audio-Visual Saliency Detection and Ranking](https://openreview.net/forum?id=0Q9zTGHOda) |        |
| [Audio-Driven Identity Manipulation for Face Inpainting](https://openreview.net/forum?id=XY8iqCpOBF) |        |
| [GROOT: Generating Robust Watermark for Diffusion-Model-Based Audio Synthesis](https://openreview.net/forum?id=wKZmm6OPoy) |        |
| [TAS: Personalized Text-guided Audio Spatialization](https://openreview.net/forum?id=5ab60yS8e0) |        |
| [Boosting Audio Visual Question Answering via Key Semantic-Aware Cues](https://openreview.net/forum?id=c4XZpv5Fdh) |        |
| [V2A-Mark: Versatile Deep Visual-Audio Watermarking for Manipulation Localization and Copyright Protection](https://openreview.net/forum?id=IRiDIMJ8Zi) |        |

## ICLR'23

### Speech

| Paper                                                        | Status |
| ------------------------------------------------------------ | ------ |
| [TranSpeech: Speech-to-Speech Translation With Bilateral Perturbation](https://openreview.net/forum?id=UVAmFAtC5ye) |        |
| [An efficient encoder-decoder architecture with top-down attention for speech separation](https://openreview.net/forum?id=fzberKYWKsI) |        |
| [Jointly Learning Visual and Auditory Speech Representations from Raw Data](https://openreview.net/forum?id=BPwIgvf5iQ) |        |
| [Bag of Tricks for Unsupervised Text-to-Speech](https://openreview.net/forum?id=SbR9mpTuBn) |        |
| [In-Situ Text-Only Adaptation of Speech Models with Low-Overhead Speech Imputations](https://openreview.net/forum?id=T2Ncx_PN2K) |        |
| [Revisiting the Entropy Semiring for Neural Speech Recognition](https://openreview.net/forum?id=SNgLnzFQeiD) |        |
| [D4AM: A General Denoising Framework for Downstream Acoustic Models](https://openreview.net/forum?id=5fvXH49wk2) |        |
| [Filter-Recovery Network for Multi-Speaker Audio-Visual Speech Separation](https://openreview.net/forum?id=fiB2RjmgwQ6) |        |
| [BigVGAN: A Universal Neural Vocoder with Large-Scale Training](https://openreview.net/forum?id=iTtGCMDEzS_) |        |
| [Continuous pseudo-labeling from the start ](https://openreview.net/forum?id=m3twGT2bAug) |        |
| [NANSY++: Unified Voice Synthesis with Neural Analysis and Synthesis](https://openreview.net/forum?id=elDEe8LYW7-) |        |
| [BAYES RISK CTC: CONTROLLABLE CTC ALIGNMENT IN SEQUENCE-TO-SEQUENCE TASKS](https://openreview.net/forum?id=Bd7GueaTxUz) |        |

### Audio

| Paper                                                        | Status |
| ------------------------------------------------------------ | ------ |
| [Token Merging: Your ViT But Faster ](https://openreview.net/forum?id=JroZRaRw7Eu) | Oral   |
| [Contrastive Audio-Visual Masked Autoencoder ](https://openreview.net/forum?id=QPtMRyk5rb) | Spot   |
| [AudioGen: Textually Guided Audio Generation](https://openreview.net/forum?id=CYK7RfcOzQ4) |        |
| [Defending against Adversarial Audio via Diffusion Model](https://openreview.net/forum?id=5-Df3tljit7) |        |
| [wav2tok: Deep Sequence Tokenizer for Audio Retrieval](https://openreview.net/forum?id=v8Mi8KU6056) |        |
| [Continual Transformers: Redundancy-Free Attention for Online Inference](https://openreview.net/forum?id=PolHquob8M7) |        |
| [GeneFace: Generalized and High-Fidelity Audio-Driven 3D Talking Face Synthesis](https://openreview.net/forum?id=YfwMIDhPccD) |        |
| [Words are all you need? Language as an approximation for human similarity judgments](https://openreview.net/forum?id=O-G91-4cMdv) |        |

## AAAI'24

useful link: https://aaai.org/wp-content/uploads/2024/02/AAAI-24_Main_2024-02-01.pdf

https://github.com/DmitryRyumin/AAAI-2024-Papers

### Speech

| Paper                                                        | Status                                                 |
| ------------------------------------------------------------ | ------------------------------------------------------ |
| Mimic: Speaking Style Disentanglement for Speech-Driven 3D Facial Animation | https://arxiv.org/abs/2312.10877                       |
| UniCATS: A Unified Context-Aware Text-to-Speech Framework with Contextual VQ-Diffusion and Vocoding | https://arxiv.org/abs/2306.07547                       |
| Multichannel AV-wav2vec2: A Framework for Learning Multichannel Multi-Modal Speech Representation | https://arxiv.org/abs/2401.03468                       |
| Visual Hallucination Elevates Speech Recognition             | https://ojs.aaai.org/index.php/AAAI/article/view/29926 |
| Spanning the Spectrum of Hatred Detection: A Persian Multi-Label Hate Speech Dataset with Annotator Rationales | https://ojs.aaai.org/index.php/AAAI/article/view/29743 |
| Restoring Speaking Lips from Occlusion for Audio-Visual Speech Recognition | https://ojs.aaai.org/index.php/AAAI/article/view/29882 |
| MM-TTS: Multi-Modal Prompt Based Style Transfer for Expressive Text-toSpeech Synthesis | https://arxiv.org/abs/2312.10687                       |
| Emotion Rendering for Conversational Speech Synthesis with Heterogeneous Graph-Based Context Modeling | https://arxiv.org/abs/2312.11947                       |
| Let There Be Sound: Reconstructing High Quality Speech from Silent Videos | https://arxiv.org/abs/2308.15256                       |
| Divergence-Guided Simultaneous Speech Translation            | https://ojs.aaai.org/index.php/AAAI/article/view/29733 |
| SECap: Speech Emotion Captioning with Large Language Model   | https://arxiv.org/abs/2312.10381                       |
| Self-Supervised Disentangled Representation Learning for Robust Target Speech Extraction | https://arxiv.org/abs/2312.10305                       |

### Audio

| Paper                                                        | Status                                                 |
| ------------------------------------------------------------ | ------------------------------------------------------ |
| AE-NeRF: Audio Enhanced Neural Radiance Field for Few Shot Talking Head Synthesis | https://arxiv.org/abs/2312.10921                       |
| V2A-Mapper: A Lightweight Solution for Vision-to-Audio Generation by Connecting Foundation Models | https://arxiv.org/abs/2308.09300                       |
| What to Remember: Self-Adaptive Continual Learning for Audio Deepfake Detection | https://arxiv.org/abs/2312.09651                       |
| Audio Generation with Multiple Conditional Diffusion Model   | https://arxiv.org/abs/2308.11940                       |
| AVSegFormer: Audio-Visual Segmentation with Transformer      | https://ojs.aaai.org/index.php/AAAI/article/view/29104 |
| Diverse and Aligned Audio-to-Video Generation via Text-to-Video Model Adaptation | https://arxiv.org/abs/2309.16429                       |
| Sample-Constrained Black Box Optimization for Audio Personalization | https://ojs.aaai.org/index.php/AAAI/article/view/28881 |
| DTF-AT: Decoupled Time-Frequency Audio Transformer for Event Classification | https://ojs.aaai.org/index.php/AAAI/article/view/29716 |
| CAVEN: An Embodied Conversational Agent for Efficient Audio-Visual Navigation in Noisy Environments | https://arxiv.org/abs/2306.04047                       |
| Learning Temporal Resolution in Spectrogram for Audio Classification | https://arxiv.org/abs/2210.01719                       |
| SoundCount: Sound Counting from Raw Audio with Dyadic Decomposition Neural Network | https://arxiv.org/abs/2312.16149                       |
| Segment beyond View: Handling Partially Missing Modality for Audio-Visual Semantic Segmentation | https://arxiv.org/abs/2312.08673                       |
| Improving Audio-Visual Segmentation with Bidirectional Generation | https://arxiv.org/abs/2308.08288                       |
| Audio Scanning Network: Bridging Time and Frequency Domains for Audio Classification | https://ojs.aaai.org/index.php/AAAI/article/view/29015 |
| Object-Aware Adaptive-Positivity Learning for Audio-Visual Question Answering | https://arxiv.org/abs/2312.12816                       |
| Prompting Segmentation with Sound Is Generalizable Audio-Visual Source Localizer | https://arxiv.org/abs/2309.07929                       |

## ACL'24

useful link: https://2024.aclweb.org/program/main_conference_papers/#long-papers

### Speech

| Paper                                                        | Authorlist                                                   | Status                                                       |
| ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **GenTranslate: Large Language Models are Generative Multilingual Speech and Machine Translators** | *Yuchen Hu, Chen Chen, Chao-Han Huck Yang, Ruizhe Li, Dong Zhang, Zhehuai Chen, EngSiong Chng* | Long, [link](https://aclanthology.org/2024.acl-long.5.pdf)   |
| **Wav2Gloss: Generating Interlinear Glossed Text from Speech** | *Taiqi He, Kwanghee Choi, Lindia Tjuatja, Nathaniel Romney Robinson, Jiatong Shi, Shinji Watanabe, Graham Neubig, David R Mortensen, Lori Levin* | https://aclanthology.org/2024.acl-long.34.pdf                |
| **A Non-autoregressive Generation Framework for End-to-End Simultaneous Speech-to-Any Translation** | *Zhengrui Ma, Qingkai Fang, Shaolei Zhang, Shoutao Guo, Yang Feng, Min zhang* | https://aclanthology.org/2024.acl-long.85.pdf                |
| **Generative Pre-trained Speech Language Model with Efficient Hierarchical Transformer** | *Yongxin Zhu, Dan Su, Liqiang He, Linli Xu, Dong Yu*         | https://aclanthology.org/2024.acl-long.97.pdf                |
| **Speech Translation with Speech Foundation Models and Large Language Models: What is There and What is Missing?** | *Marco Gaido, Sara Papi, Matteo Negri, Luisa Bentivogli*     | https://aclanthology.org/2024.acl-long.789.pdf               |
| **StreamAtt: Direct Streaming Speech-to-Text Translation with Attention-based Audio History Selection** | *Sara Papi, Marco Gaido, Matteo Negri, Luisa Bentivogli*     | https://aclanthology.org/2024.acl-long.202.pdf               |
| **Speech vs. Transcript: Does It Matter for Human Annotators in Speech Summarization?** | *Roshan Sharma, Suwon Shon, Mark Lindsey, Hira Dhamyal, Bhiksha Raj* | https://aclanthology.org/2024.acl-long.790.pdf               |
| **LLM Knows Body Language, Too: Translating Speech Voices into Human Gestures** | *Chenghao Xu, Guangtao Lyu, Jiexi Yan, Muli Yang, Cheng Deng* | https://aclanthology.org/2024.acl-long.273.pdf               |
| **RepCodec: A Speech Representation Codec for Speech Tokenization** | *Zhichao Huang, Chutong Meng, Tom Ko*                        | https://aclanthology.org/2024.acl-long.314.pdf               |
| **Error-preserving Automatic Speech Recognition of Young English Learners‚Äô Language** | *Janick Michot, Manuela H√ºrlimann, Jan Milan Deriu, Luzia Sauer, Katsiaryna Mlynchyk, Mark Cieliebak* | https://aclanthology.org/2024.acl-long.348.pdf               |
| **Can We Achieve High-quality Direct Speech-to-Speech Translation without Parallel Speech Data?** | *Qingkai Fang, Shaolei Zhang, Zhengrui Ma, Min zhang, Yang Feng* | https://aclanthology.org/2024.acl-long.392.pdf               |
| **Multimodal Contextualized Semantic Parsing from Speech**   | *Jordan Voas, David Harwath, Ray Mooney*                     | https://aclanthology.org/2024.acl-long.398.pdf               |
| **SpikeVoice: High-Quality Text-to-Speech Via Efficient Spiking Neural Network** | *Kexin Wang, Jiahong Zhang, Yong Ren, Man Yao, Di Shang, Bo XU, Guoqi Li* | https://aclanthology.org/2024.acl-long.429.pdf               |
| **Speech Sense Disambiguation: Tackling Homophone Ambiguity in End-to-End Speech Translation** | *Tengfei Yu, Xuebo Liu, Liang Ding, Kehai Chen, Dacheng Tao, Min Zhang* | https://aclanthology.org/2024.acl-long.435.pdf               |
| **Label-Synchronous Neural Transducer for E2E Simultaneous Speech Translation** | *Keqi Deng, Phil Woodland*                                   | https://aclanthology.org/2024.acl-long.448.pdf               |
| **Language Complexity and Speech Recognition Accuracy: Orthographic Complexity Hurts, Phonological Complexity Doesn‚Äôt** | *Chihiro Taguchi, David Chiang*                              | https://aclanthology.org/2024.acl-long.827.pdf               |
| **Speech language models lack important brain-relevant semantics** | *SUBBA REDDY OOTA, Emin √áelik, Fatma Deniz, Mariya Toneva*   | https://aclanthology.org/2024.acl-long.462.pdf               |
| **StreamSpeech: Simultaneous Speech-to-Speech Translation with Multi-task Learning** | *Shaolei Zhang, Qingkai Fang, Shoutao Guo, Zhengrui Ma, Min zhang, Yang Feng* | https://aclanthology.org/2024.acl-long.485.pdf               |
| **NaijaHate: Evaluating Hate Speech Detection on Nigerian Twitter Using Representative Data** | *Manuel Tonneau, Pedro Vitor Quinta de Castro, Karim Lasri, Ibrahim Sambo Farouq, Lakshmi Subramanian, Victor Orozco-Olvera, Samuel Fraiberger* | https://aclanthology.org/2024.acl-long.488v2.pdf             |
| **Uni-Dubbing: Zero-Shot Speech Synthesis from Visual Articulation** | *Songju Lei, Xize Cheng, Mengjiao Lyu, Jianqiao Hu, Jintao Tan, Runlin Liu, Lingyu Xiong, Tao Jin, Xiandong Li, Zhou Zhao* | https://aclanthology.org/2024.acl-long.543.pdf               |
| **OWSM-CTC: An Open Encoder-Only Speech Foundation Model for Speech Recognition, Translation, and Language Identification** | *Yifan Peng, Yui Sudo, Muhammad Shakeel, Shinji Watanabe*    | https://aclanthology.org/2024.acl-long.549.pdf               |
| **Don‚Äôt Go To Extremes: Revealing the Excessive Sensitivity and Calibration Limitations of LLMs in Implicit Hate Speech Detection** | *Min Zhang, Jianfeng He, Taoran Ji, Chang-Tien Lu*           | https://aclanthology.org/2024.acl-long.652.pdf               |
| **Structured Tree Alignment for Evaluation of (Speech) Constituency Parsing** | *Freda Shi, Kevin Gimpel, Karen Livescu*                     | https://aclanthology.org/2024.acl-long.666.pdf               |
| **VoiceCraft: Zero-Shot Speech Editing and Text-to-Speech in the Wild** | *Puyuan Peng, Po-Yao Huang, Shang-Wen Li, Abdelrahman Mohamed, David Harwath* | https://aclanthology.org/2024.acl-long.673.pdf               |
| **A Community-Centric Perspective for Characterizing and Detecting Anti-Asian Violence-Provoking Speech** | *Gaurav Verma, Rynaa Grover, Jiawei Zhou, Binny Mathew, Jordan Kraemer, Munmun De Choudhury, Srijan Kumar* | https://aclanthology.org/2024.acl-long.684.pdf               |
| **XLAVS-R: Cross-Lingual Audio-Visual Speech Representation Learning for Noise-Robust Speech Perception** | *HyoJung Han, Mohamed Anwar, Juan Pino, Wei-Ning Hsu, Marine Carpuat, Bowen Shi, Changhan Wang* | https://aclanthology.org/2024.acl-long.697.pdf               |
| **MobileSpeech: A Fast and High-Fidelity Framework for Mobile Zero-Shot Text-to-Speech** | *Shengpeng Ji, Ziyue Jiang, Wang Hanting, Jialung Zuo, Zhou Zhao* | https://aclanthology.org/2024.acl-long.733.pdf               |
| **The MERSA Dataset and a Transformer-Based Approach for Speech Emotion Recognition** | *Enshi Zhang, Rafael Trujillo, Christian Poellabauer*        | https://aclanthology.org/2024.acl-long.752.pdf               |
| **Growing Trees on Sounds: Assessing Strategies for End-to-End Dependency Parsing of Speech** | *Adrien Pupier, Maximin Coavoux, J√©r√¥me Goulian, Benjamin Lecouteux* | Short, [link](https://aclanthology.org/2024.acl-short.22.pdf) |
| **Explainability and Hate Speech: Structured Explanations Make Social Media Moderators Faster** | *Agostina Calabrese, Leonardo Neves, Neil Shah, Maarten W. Bos, Bj√∂rn Ross, Mirella Lapata, Francesco Barbieri* | https://aclanthology.org/2024.acl-short.38.pdf               |
| **On the Semantic Latent Space of Diffusion-Based Text-To-Speech Models** | *Miri Varshavsky, Roy Hirsch, Regev Cohen, Tomer Golany, Daniel Freedman, Ehud Rivlin* | https://aclanthology.org/2024.acl-short.24.pdf               |

### Audio

| Paper                                                        | Authorlist                                                   | Status                                                       |
| ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **AIR-Bench: Benchmarking Large Audio-Language Models via Generative Comprehension** | *Qian Yang, Jin Xu, Wenrui Liu, Yunfei Chu, Ziyue Jiang, Xiaohuan Zhou, Yichong Leng, Yuanjun Lv, Zhou Zhao, Chang Zhou, Jingren Zhou* | Long, [link](https://aclanthology.org/2024.acl-long.109.pdf) |
| **StreamAtt: Direct Streaming Speech-to-Text Translation with Attention-based Audio History Selection** | *Sara Papi, Marco Gaido, Matteo Negri, Luisa Bentivogli*     | https://aclanthology.org/2024.acl-long.202.pdf               |
| **M$^3$AV: A Multimodal, Multigenre, and Multipurpose Audio-Visual Academic Lecture Dataset** | *Zhe Chen, Heyang Liu, Wenyi Yu, Guangzhi Sun, Hongcheng Liu, Ji Wu, Chao Zhang, Yu Wang, Yanfeng Wang* | https://aclanthology.org/2024.acl-long.489.pdf               |
| **XLAVS-R: Cross-Lingual Audio-Visual Speech Representation Learning for Noise-Robust Speech Perception** | *HyoJung Han, Mohamed Anwar, Juan Pino, Wei-Ning Hsu, Marine Carpuat, Bowen Shi, Changhan Wang* | https://aclanthology.org/2024.acl-long.697.pdf               |

## EMNLP'24

useful link: https://2024.emnlp.org/program/accepted_main_conference/

https://2024.emnlp.org/program/accepted_findings/

### Speech

| Paper                                                        | Authorlist                                                   | Status                                                       |
| ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **When LLMs Meets Acoustic Landmarks: An Efficient Approach to Integrate Speech into Large Language Models for Depression Detection** | Xiangyu Zhang, Hexin Liu, Kaishuai Xu, Qiquan Zhang, Daijiao Liu, Beena Ahmed, Julien Epps | Main, [link](https://aclanthology.org/2024.emnlp-main.8.pdf) |
| **Speaking in Wavelet Domain: A Simple and Efficient Approach to Speed up Speech Diffusion Model** | Xiangyu Zhang, Daijiao Liu, Hexin Liu, Qiquan Zhang, Hanyu Meng, Leibny Paola Garcia Perera, EngSiong Chng, Lina Yao | https://aclanthology.org/2024.emnlp-main.9.pdf               |
| **Scaling Properties of Speech Language Models**             | Santiago Cuervo, Ricard Marxer                               | https://aclanthology.org/2024.emnlp-main.21.pdf              |
| **EmphAssess : a Prosodic Benchmark on Assessing Emphasis Transfer in Speech-to-Speech Models** | Maureen de Seyssel, Antony D‚ÄôAvirro, Adina Williams, Emmanuel Dupoux | https://aclanthology.org/2024.emnlp-main.30.pdf              |
| **Is Safer Better? The Impact of Guardrails on the Argumentative Strength of LLMs in Hate Speech Countering** | Helena Bonaldi, Greta Damo, Nicol√°s Benjam√≠n Ocampo, Elena Cabrio, Serena Villata, Marco Guerini | https://aclanthology.org/2024.emnlp-main.201.pdf             |
| **AlignCap: Aligning Speech Emotion Captioning to Human Preferences** | Ziqi Liang, Haoxiang Shi, Hanhui Chen                        | https://aclanthology.org/2024.emnlp-main.224.pdf             |
| **F$^2$RL: Factuality and Faithfulness Reinforcement Learning Framework for Claim-Guided Evidence-Supported Counterspeech Generation** | Haiyang Wang, Yuchen Pan, Xin Song, Xuechen Zhao, Minghao Hu, Bin Zhou | https://aclanthology.org/2024.emnlp-main.255.pdf             |
| **Outcome-Constrained Large Language Models for Countering Hate Speech** | Lingzi Hong, Pengcheng Luo, Eduardo Blanco, Xiaoying Song    | https://aclanthology.org/2024.emnlp-main.260.pdf             |
| **On Mitigating Performance Disparities in Multilingual Speech Recognition** | Monorama Swain, Anna Katrine van Zee, Anders S√∏gaard         | https://aclanthology.org/2024.emnlp-main.323.pdf             |
| **Methods of Automatic Matrix Language Determination for Code-Switched Speech** | Olga Iakovenko, Thomas Hain                                  | https://aclanthology.org/2024.emnlp-main.330.pdf             |
| **EH-MAM: Easy-to-Hard Masked Acoustic Modeling for Self-Supervised Speech Representation Learning** | Ashish Seth, Ramaneswaran S, S Sakshi, Sonal Kumar, Sreyan Ghosh, Dinesh Manocha | https://aclanthology.org/2024.emnlp-main.366.pdf             |
| **Muting Whisper: A Universal Acoustic Adversarial Attack on Speech Foundation Models** | Vyas Raina, Rao Ma, Charles McGhee, Kate Knill, Mark Gales   | https://aclanthology.org/2024.emnlp-main.430.pdf             |
| **Bridging Modalities: Enhancing Cross-Modality Hate Speech Detection with Few-Shot In-Context Learning** | Ming Shan Hee, Aditi Kumaresan, Roy Ka-Wei Lee               | https://aclanthology.org/2024.emnlp-main.445.pdf             |
| **Task Arithmetic can Mitigate Synthetic-to-Real Gap in Automatic Speech Recognition** | Hsuan Su, Hua Farn, Fan-Yun Sun, Shang-Tse Chen, Hung-yi Lee | https://aclanthology.org/2024.emnlp-main.503.pdf             |
| **ESC: Efficient Speech Coding with Cross-Scale Residual Vector Quantized Transformers** | Yuzhe Gu, Enmao Diao                                         | https://aclanthology.org/2024.emnlp-main.562.pdf             |
| **Towards Robust Speech Representation Learning for Thousands of Languages** | William Chen, Wangyou Zhang, Yifan Peng, Xinjian Li, Jinchuan Tian, Jiatong Shi, Xuankai Chang, Soumi Maiti, Karen Livescu, Shinji Watanabe | https://aclanthology.org/2024.emnlp-main.570.pdf             |
| **Speechworthy Instruction-tuned Language Models**           | Hyundong Justin Cho, Nicolaas Paul Jedema, Leonardo F. R. Ribeiro, Karishma Sharma, Pedro Szekely, Alessandro Moschitti, Ruben Janssen, Jonathan May | https://aclanthology.org/2024.emnlp-main.595.pdf             |
| **Towards Probing Speech-Specific Risks in Large Multimodal Models: A Taxonomy, Benchmark, and Insights** | Hao Yang, Lizhen Qu, Ehsan Shareghi, Reza Haf                | https://aclanthology.org/2024.emnlp-main.614.pdf             |
| **Integrating Argumentation and Hate-Speech-based Techniques for Countering Misinformation** | Sougata Saha, Rohini Srihari                                 | https://aclanthology.org/2024.emnlp-main.622.pdf             |
| **Unveiling the Role of Pretraining in Direct Speech Translation** | Belen Alastruey, Gerard I. G√°llego, Marta R. Costa-juss√†     | https://aclanthology.org/2024.emnlp-main.630.pdf             |
| **Multi-Level Cross-Modal Alignment for Speech Relation Extraction** | Liang Zhang, Zhen Yang, Biao Fu, Ziyao Lu, Liangying Shao, Shiyu Liu, Fandong Meng, Jie Zhou, Xiaoli Wang, Jinsong Su | https://aclanthology.org/2024.emnlp-main.668.pdf             |
| **Self-Powered LLM Modality Expansion for Large Speech-Text Models** | Tengfei Yu, Xuebo Liu, Zhiyi Hou, Liang Ding, Dacheng Tao, Min Zhang | https://aclanthology.org/2024.emnlp-main.690.pdf             |
| **Optimizing Rare Word Accuracy in Direct Speech Translation with a Retrieval-and-Demonstration Approach** | Siqi Li, Danni Liu, Jan Niehues                              | https://aclanthology.org/2024.emnlp-main.708.pdf             |
| **Towards an Open-Source Speech Foundation Model for EU: 950,000 Hours of Open-Source Compliant Speech Data for EU Languages** | Marco Gaido, Sara Papi, Luisa Bentivogli, Alessio Brutti, Mauro Cettolo, Roberto Gretter, Marco Matassoni, Mohamed Nabih, Matteo Negri | https://aclanthology.org/2024.emnlp-main.771.pdf             |
| **VHASR: A Multimodal Speech Recognition System With Vision Hotwords** | Jiliang Hu, Zuchao Li, Ping Wang, Haojun Ai, Lefei Zhang, hai zhao | https://aclanthology.org/2024.emnlp-main.821.pdf             |
| **AudioVSR: Enhancing Video Speech Recognition with Audio Data** | Xiaoda Yang, Xize Cheng, Jiaqi Duan, Hongshun Qiu, Minjie Hong, Minghui Fang, Shengpeng Ji, Jialong Zuo, Zhiqing Hong, Zhimeng Zhang, Tao Jin | https://aclanthology.org/2024.emnlp-main.858.pdf             |
| **Hate Personified: Investigating the role of LLMs in content moderation pipeline for hate speech** | Sarah Masud, Sahajpreet Singh, Viktor Hangya, Alexander Fraser, Tanmoy Chakraborty | https://aclanthology.org/2024.emnlp-main.886.pdf             |
| **Please note that I‚Äôm just an AI: Analysis of Behavior Patterns of LLMs in (Non-)offensive Speech Identification** | Esra D√∂nmez, Thang Vu, Agnieszka Falenska                    | https://aclanthology.org/2024.emnlp-main.1019.pdf            |
| **BLSP-Emo: Towards Empathetic Large Speech-Language Models** | Chen Wang, Minpeng Liao, Zhongqiang Huang, Junhong Wu, Chengqing Zong, Jiajun Zhang | https://aclanthology.org/2024.emnlp-main.1070.pdf            |
| **Delving into Qualitative Implications of Synthetic Data for Hate Speech Detection** | Camilla Casula, Sebastiano Vecellio Salto, Alan Ramponi, Sara Tonelli |                                                              |
| **Continual Test-time Adaptation for End-to-end Speech Recognition on Noisy Speech** | Guan-Ting Lin, Wei Ping Huang, Hung-yi Lee                   |                                                              |
| **Interventional Speech Noise Injection for ASR Generalizable Spoken Language Understanding** | YeonJoon Jung, Jaeseong Lee, Seungtaek Choi, Dohyeon Lee, Minsoo Kim, seung-won hwang |                                                              |
| **Bayesian Example Selection Improves In-Context Learning for Speech, Text, and Visual Modalities** | Siyin Wang, Chao-Han Huck Yang, Ji Wu, Chao Zhang            |                                                              |
| **PREDICT: Multi-Agent-based Debate Simulation for Generalized Hate Speech Detection** | Someen Park, Jaehoon Kim, Seungwan Jin, Sohyun Park, Kyungsik Han |                                                              |
| **TokenVerse: Unifying Speech and NLP Tasks via Transducer-based ASR** | Shashi Kumar, Srikanth Madikeri, Juan Pablo Zuluaga Gomez, Iuliia Thorbecke, Esa√∫ VILLATORO-TELLO, Sergio Burdisso, Petr Motlicek, Karthik Pandia D S, Aravind Ganapathiraju |                                                              |
| **Twists, Humps, and Pebbles: Multilingual Speech Recognition Models Exhibit Gender Performance Gaps** | Giuseppe Attanasio, Beatrice Savoldi, Dennis Fucci, Dirk Hovy |                                                              |
| **Casablanca: Data and Models for Multidialectal Arabic Speech Recognition** | Bashar Talafha, Karima Kadaoui, Samar Mohamed Magdy, Mariem Habiboullah, Chafei Mohamed Chafei, Ahmed Oumar El-Shangiti, et.al. |                                                              |
| **SpeechQE: Estimating the Quality of Direct Speech Translation** | HyoJung Han, Kevin Duh, Marine Carpuat                       |                                                              |
| **Simul-MuST-C: Simultaneous Multilingual Speech Translation Corpus Using Large Language Model** | Mana Makinae, Yusuke Sakai, Hidetaka Kamigaito, Taro Watanabe |                                                              |
| **Is Child-Directed Speech Effective Training Data for Language Models?** | Steven Y. Feng, Noah Goodman, Michael Frank                  |                                                              |
| **HateCOT: An Explanation-Enhanced Dataset for Generalizable Offensive Speech Detection via Large Language Models** | Huy Nghiem, Hal Daum√© III                                    | Findings                                                     |
| **PolyWER: A Holistic Evaluation Framework for Code-Switched Speech Recognition** | Karima Kadaoui, Maryam Al Ali, Hawau Olamide Toyin, Ibrahim Mohammed, Hanan Aldarmaki |                                                              |
| **STTATTS: Unified Speech-To-Text And Text-To-Speech Model** | Hawau Olamide Toyin, Hao Li, Hanan Aldarmaki                 |                                                              |
| **Contextualized Graph Representations for Generating Counter-Narrative against Hate Speech** | Selene Baez Santamaria, Helena Gomez Adorno, Ilia Markov     |                                                              |
| **LaRA: Large Rank Adaptation for Speech and Text Cross-Modal Learning in Large Language Models** | Zuhair hasan shaik, Pradyoth Hegde, Prashant Bannulmath, Deepak K T |                                                              |
| **MultiVerse: Efficient and Expressive Zero-Shot Multi-Task Text-to-Speech** | Taejun Bak, Youngsik Eom, SeungJae Choi, Young-Sun Joo       |                                                              |
| **Where Visual Speech Meets Language: VSP-LLM Framework for Efficient and Context-Aware Visual Speech Processing** | Jeonghun Yeo, Seunghee Han, Minsu Kim, Yong Man Ro           |                                                              |
| **Adversarial Attacks on Parts of Speech: An Empirical Study in Text-to-Image Generation** | G M Shahariar, Jia Chen, Jiachen Li, Yue Dong                |                                                              |
| **Breaking the Boundaries: A Unified Framework for Chinese Named Entity Recognition Across Text and Speech** | Jinzhong Ning, Yuanyuan Sun, Bo Xu, Zhihao Yang, Ling Luo, Hongfei Lin |                                                              |
| **Audio-Based Linguistic Feature Extraction for Enhancing Multi-lingual and Low-Resource Text-to-Speech** | Youngjae Kim, Yejin Jeon, Gary Lee                           |                                                              |
| **Modeling Gender and Dialect Bias in Automatic Speech Recognition** | Camille Harris, Chijioke Mgbahurike, Neha Kumar, Diyi Yang   |                                                              |
| **LLM generated responses to mitigate the impact of hate speech** | Jakub Podolak, Szymon ≈Åukasik, Pawe≈Ç Balawender, Jan Ossowski, Jan Piotrowski, Katarzyna BƒÖkowicz, Piotr Sankowski |                                                              |
| **BLASER 2.0: a metric for evaluation and quality estimation of massively multilingual speech and text translation** | David Dale, Marta R. Costa-juss√†                             |                                                              |
| **Textless Speech-to-Speech Translation With Limited Parallel Data** | Anuj Diwan, Anirudh Srinivasan, David Harwath, Eunsol Choi   |                                                              |
| **PSLM: Parallel Generation of Text and Speech with LLMs for Low-Latency Spoken Dialogue Systems** | Kentaro Mitsui, Koh Mitsuda, Toshiaki Wakatsuki, Yukiya Hono, Kei Sawada |                                                              |
| **Bahasa Harmony: A Comprehensive Dataset for Bahasa Text-to-Speech Synthesis with Discrete Codec Modeling of EnGen-TTS.** | Onkar Kishor Susladkar, Vishesh Tripathi, Biddwan Ahmed      |                                                              |
| **Recent Advances in Online Hate Speech Moderation: Multimodality and the Role of Large Models** | Ming Shan Hee, Shivam Sharma, RUI CAO, Palash Nandi, Preslav Nakov, Tanmoy Chakraborty, Roy Ka-Wei Lee |                                                              |
| **WavLLM: Towards Robust and Adaptive Speech Large Language Model** | Shujie HU, Long Zhou, Shujie LIU, Sanyuan Chen, Lingwei Meng, Hongkun Hao, Jing Pan, Xunying Liu, Jinyu Li, Sunit Sivasankaran, Linquan Liu, Furu Wei |                                                              |

### Audio

| Paper                                                        | Authorlist                                                   | Status   |
| ------------------------------------------------------------ | ------------------------------------------------------------ | -------- |
| **IDEAW: Robust Neural Audio Watermarking with Invertible Dual-Embedding** | Pengcheng Li, Xulong Zhang, Jing Xiao, Jianzong Wang         | Main     |
| **Cross-Domain Audio Deepfake Detection: Dataset and Analysis** | Yuang Li, Min Zhang, Mengxin Ren, Xiaosong Qiao, Miaomiao Ma, Daimeng Wei, Hao Yang |          |
| **GAMA: A Large Audio-Language Model with Advanced Audio Understanding and Complex Reasoning Abilities** | Sreyan Ghosh, Sonal Kumar, Ashish Seth, Chandra Kiran Reddy Evuru, Utkarsh Tyagi, S Sakshi, Oriol Nieto, Ramani Duraiswami, Dinesh Manocha |          |
| **OpenSep: Leveraging Large Language Models with Textual Inversion for Open World Audio Separation** | Tanvir Mahmud, Diana Marculescu                              |          |
| **AudioVSR: Enhancing Video Speech Recognition with Audio Data** | Xiaoda Yang, Xize Cheng, Jiaqi Duan, Hongshun Qiu, Minjie Hong, Minghui Fang, Shengpeng Ji, Jialong Zuo, Zhiqing Hong, Zhimeng Zhang, Tao Jin |          |
| **PALM: Few-Shot Prompt Learning for Audio Language Models** | Asif Hanif, Maha Tufail Agro, Mohammad Areeb Qazi, Hanan Aldarmaki |          |
| **Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large Language Models** | Yiming Chen, Xianghu Yue, Xiaoxue Gao, Chen Zhang, Luis Fernando D‚ÄôHaro, Robby T. Tan, Haizhou Li | Findings |
| **AlanaVLM: A Multimodal Embodied AI Foundation Model for Egocentric Video Understanding** | Alessandro Suglia, Claudio Greco, Katie Baker, Jose L. Part, Ioannis Papaioannou, Arash Eshghi, Ioannis Konstas, Oliver Lemon |          |
| **Unveiling Hallucination in Text, Image, Video, and Audio Foundation Models: A Comprehensive Review** | Pranab Sahoo, Prabhash Meharia, Akash Ghosh, Sriparna Saha, Vinija Jain, Aman Chadha |          |
| **Audio-Based Linguistic Feature Extraction for Enhancing Multi-lingual and Low-Resource Text-to-Speech** | Youngjae Kim, Yejin Jeon, Gary Lee                           |          |
| **SaSR-Net: Source-Aware Semantic Representation Network for Enhancing Audio-Visual Question Answering** | Tianyu Yang, Yiyang Nan, Lisen Dai, Zhenwen Liang, Yapeng Tian, Xiangliang Zhang |          |
| **PyramidCodec: Hierarchical Codec for Long-form Music Generation in Audio Domain** | Jianyi Chen, Zheqi DAI, Zhen Ye, Xu Tan, Qifeng Liu, Yike Guo, Wei Xue |          |

## NAACL'25

useful link: https://2025.naacl.org/program/accepted_papers/

### Speech

| Paper                                                        | Authorlist                                                   | Status   |
| ------------------------------------------------------------ | ------------------------------------------------------------ | -------- |
| **Robust and Unbounded Length Generalization in Autoregressive Transformer-Based Text-to-Speech** | Eric Battenberg, RJ Skerry-Ryan, Daisy Stanton, Soroosh Mariooryad, Matt Shannon, Julian Salazar, David Teh-Hwa Kao |          |
| **Decoding Hate: Exploring Language Models‚Äô Reactions to Hate Speech** | Paloma Piot, Javier Parapar                                  |          |
| **Multi$^3$Hate: Multimodal, Multilingual, and Multicultural Hate Speech Detection with Vision‚ÄìLanguage Models** | Minh Duc Bui, Katharina von der Wense, Anne Lauscher         |          |
| **CSEval: Towards Automated, Multi-Dimensional, and Reference-Free Counterspeech Evaluation using Auto-Calibrated LLMs** | Amey Hengle, Aswini Kumar Padhi, Anil Bandhakavi, Tanmoy Chakraborty |          |
| **MAD Speech: Measures of Acoustic Diversity of Speech**     | Matthieu Futeral, Andrea Agostinelli, Marco Tagliasacchi, Neil Zeghidour, Eugene Kharitonov |          |
| **Afrispeech-Dialog: A Benchmark Dataset for Spontaneous English Conversations in Healthcare and Beyond** | Mardhiyah Sanni, Tassallah Abdullahi, Devendra Deepak Kayande, Emmanuel Ayodele, Naome A Etori, Michael Samwel Mollel, Moshood O. Yekini, Chibuzor Okocha, Lukman Enegi Ismaila, Folafunmi Omofoye, Boluwatife A. Adewale, Tobi Olatunji |          |
| **Wav2Prompt: End-to-End Speech Prompt Learning and Task-based Fine-tuning for Text-based LLMs** | Keqi Deng, Guangzhi Sun, Phil Woodland                       |          |
| **On the Role of Speech Data in Reducing Toxicity Detection Bias** | Samuel Bell, Mariano Coria Meglioli, Megan Richards, Eduardo S√°nchez, Christophe Ropers, Skyler Wang, Adina Williams, Levent Sagun, Marta R. Costa-juss√† |          |
| **Leveraging Allophony in Self-Supervised Speech Models for Atypical Pronunciation Assessment** | Kwanghee Choi, Eunjung Yeo, Kalvin Chang, Shinji Watanabe, David R Mortensen |          |
| **StyleTTS-ZS: Efficient High-Quality Zero-Shot Text-to-Speech Synthesis with Distilled Time-Varying Style Diffusion** | Yinghao Aaron Li, Xilin Jiang, Cong Han, Nima Mesgarani      |          |
| **AfriHate: A Multilingual Collection of Hate Speech and Abusive Language Datasets for African Languages** | Shamsuddeen Hassan Muhammad, Idris Abdulmumin, Abinew Ali Ayele, David Ifeoluwa Adelani, Ibrahim Said Ahmad, Saminu Mohammad Aliyu, Paul R√∂ttger, Abigail Oppong, Andiswa Bukula, et, al |          |
| **Prepending or Cross-Attention for Speech-to-Text? An Empirical Comparison** | Tsz Kin Lam, Marco Gaido, Sara Papi, Luisa Bentivogli, Barry Haddow |          |
| **ProSE: Diffusion Priors for Speech Enhancement**           | Sonal Kumar, Sreyan Ghosh, Utkarsh Tyagi, Anton Jeran Ratnarajah, Chandra Kiran Reddy Evuru, Ramani Duraiswami, Dinesh Manocha |          |
| **VoiceTextBlender: Augmenting Large Language Models with Speech Capabilities via Single-Stage Joint Speech-Text Supervised Fine-Tuning** | Yifan Peng, Krishna C Puvvada, Zhehuai Chen, Piotr Zelasko, He Huang, Kunal Dhawan, Ke Hu, Shinji Watanabe, Jagadeesh Balam, Boris Ginsburg |          |
| **DyPCL: Dynamic Phoneme-level Contrastive Learning for Dysarthric Speech Recognition** | Wonjun Lee, Solee Im, Heejin Do, Yunsu Kim, Jungseul Ok, Gary Lee |          |
| **How do Multimodal Foundation Models Encode Text and Speech? An Analysis of Cross-Lingual and Cross-Modal Representations** | Hyunji Lee, Danni Liu, Supriti Sinhamahapatra, Jan Niehues   | short    |
| **Developing multilingual speech synthesis system for Ojibwe, Mi‚Äôkmaq, and Maliseet** | Shenran Wang, Changbing Yang, Michael l parkhill, Chad Quinn, Christopher Hammerly, Jian Zhu |          |
| **Cross-Lingual Transfer Learning for Speech Translation**   | Rao Ma, Mengjie Qian, Yassir Fathullah, Siyuan Tang, Mark Gales, Kate Knill |          |
| **kNN Retrieval for Simple and Effective Zero-Shot Multi-speaker Text-to-Speech** | Karl El Hajal, Ajinkya Kulkarni, Enno Hermann, Mathew Magimai Doss |          |
| **WaveFM: A High-Fidelity and Efficient Vocoder Based on Flow Matching** | Tianze Luo, Xingchen Miao, Wenbo Duan                        |          |
| **DiVISe: Direct Visual-Input Speech Synthesis Preserving Speaker Characteristics And Intelligibility** | Yifan Liu, Yu Fang, Zhouhan Lin                              | Findings |
| **BanTH: A Multi-label Hate Speech Detection Dataset for Transliterated Bangla** | Fabiha Haider, Fariha Tanjim Shifat, Md Farhan Ishmam, Md Sakib Ul Rahman Sourove, Deeparghya Dutta Barua, Md Fahim, Md Farhad Alam Bhuiyan |          |
| **CDB: A Unified Framework for Hope Speech Detection Through Counterfactual, Desire and Belief** | Tulio Ferreira Leite da Silva, Gonzalo Freijedo Aduna, Farah Benamara, Alda Mari, Zongmin Li, Li Yue, Jian Su |          |
| **Untangling Hate Speech Definitions: A Semantic Componential Analysis Across Cultures and Domains** | Katerina Korre, Arianna Muti, Federico Ruggeri, Alberto Barr√≥n-Cede√±o |          |
| **Exploring Large Language Models for Hate Speech Detection in Rioplatense Spanish** | Juan Manuel P√©rez, Paula Miguel, Viviana Cotik               |          |
| **Unsupervised Speech-text word-level alignment with Dynamic Programming** | Tianshu Yu, Zihan Gong, Minghuan Tan, Guhong Chen, Min Yang  |          |
| **Prompt-Guided Selective Masking Loss for Context-Aware Emotive Text-to-Speech** | Yejin Jeon, Youngjae Kim, Jihyun Lee, Gary Lee               |          |
| **Echoes of Discord: Forecasting Hater Reactions to Counterspeech** | Xiaoying Song, Sharon Lisseth Perez, Xinchen Yu, Eduardo Blanco, Lingzi Hong |          |
| **Continuous Speech Tokenizer in Text To Speech**            | Yixing Li, Ruobing Xie, Xingwu Sun, Yu Cheng, Zhanhui Kang   |          |
| **CA\*: Addressing Evaluation Pitfalls in Computation-Aware Latency for Simultaneous Speech Translation** | Xi Xu, Wenda Xu, Siqi Ouyang, Lei Li                         |          |
| **Gender Bias in Instruction-Guided Speech Synthesis Models** | Chun-Yi Kuan, Hung-yi Lee                                    |          |
| **Yeah, Un, Oh: Continuous and Real-time Backchannel Prediction with Fine-tuning of Voice Activity Projection** | Koji Inoue, Divesh Lala, Gabriel Skantze, Tatsuya Kawahara   | voice    |
| **Playing with Voices: Tabletop Role-Playing Game Recordings as a Diarization Challenge** | Lian Remme, Kevin Tang                                       | voice    |

### Audio

| Paper                                                        | Authorlist                                                   | Status |
| ------------------------------------------------------------ | ------------------------------------------------------------ | ------ |
| **Ihquin tlahtouah in Tetelahtzincocah: An annotated, multi-purpose audio and text corpus of Western Sierra Puebla Nahuatl** | Robert Pugh, Cheyenne Wing, Mar√≠a Ximena Ju√°rez Huerta, Angeles M√°rquez Hernandez, Francis M. Tyers |        |
| **PAT: Parameter-Free Audio-Text Aligner to Boost Zero-Shot Audio Classification** | Ashish Seth, Ramaneswaran Selvakumar, Sonal Kumar, Sreyan Ghosh, Dinesh Manocha |        |
| **AudioBench: A Universal Benchmark for Audio Large Language Models** | Bin Wang, Xunlong Zou, Geyu Lin, Shuo Sun, Zhuohan Liu, Wenyu Zhang, Zhengyuan Liu, AiTi Aw, Nancy F. Chen |        |
| **Audio Is the Achilles‚Äô Heel: Red Teaming Audio Large Multimodal Models** | Hao Yang, Lizhen Qu, Ehsan Shareghi, Gholamreza Haffari      |        |
| **Do Audio-Language Models Understand Linguistic Variations?** | Ramaneswaran Selvakumar, Sonal Kumar, Hemant Kumar Giri, Nishit Anand, Ashish Seth, Sreyan Ghosh, Dinesh Manocha |        |
| **Comprehensive Layer-wise Analysis of SSL Models for Audio Deepfake Detection** | Yassine El Kheir, Younes Samih, Suraj Maharjan, Tim Polzehl, Sebastian M√∂ller |        |
| **Audio Description Generation in the Era of LLMs and VLMs: A Review of Transferable Generative AI Technologies** | Yingqiang Gao, Lukas Fischer, Alexa Lintner, Sarah Ebling    |        |
| **Synthetic Audio Helps for Cognitive State Tasks**          | Adil Soubki, John Murzaku, Peter Zeng, Owen Rambow           |        |

## AAAI'25

### Speech

| Paper                                                        | Authorlist                                                   | Status |
| ------------------------------------------------------------ | ------------------------------------------------------------ | ------ |
| [ELLA-V: Stable Neural Codec Language Modeling with Alignment-Guided Sequence Reordering](https://ojs.aaai.org/index.php/AAAI/article/view/34703) | Yakun Song, Zhuo Chen, Xiaofei Wang, Ziyang Ma, Xie Chen     |        |
| [Language model can listen while speaking](https://ojs.aaai.org/index.php/AAAI/article/view/34665) | Ziyang Ma, Yakun Song, Chenpeng Du, Jian Cong, Zhuo Chen, Yuping Wang, Yuxuan Wang, Xie Chen |        |
| [VQTalker: Towards Multilingual Talking Avatars through Facial Motion Tokenization](https://ojs.aaai.org/index.php/AAAI/article/view/32595) | Tao Liu, Ziyang Ma, Qi Chen, Feilong Chen, Shuai Fan, Xie Chen, Kai Yu |        |
| [Speech Recognition Meets Large Language Model: Benchmarking, Models, and Exploration](https://ojs.aaai.org/index.php/AAAI/article/view/34666) | Ziyang Ma, Guanrou Yang, Yifan Yang, Zhifu Gao, Jiaming Wang, Zhihao Du, Fan Yu, Qian Chen, Siqi Zheng, Shiliang Zhang, Xie Chen |        |
| [DIDiffGes: Decoupled Semi-Implicit Diffusion Models for Real-time Gesture Generation from Speech](https://arxiv.org/abs/2503.17059) |                                                              |        |
| [FaceSpeak: Expressive and High-Quality Speech Synthesis from Human Portraits of Different Styles](https://arxiv.org/abs/2501.03181) |                                                              |        |
| [Large Language Models Are Read/Write Policy-Makers for Simultaneous Generation](https://arxiv.org/abs/2501.00868) |                                                              |        |
| [SECodec: Structural Entropy-based Compressive Speech Representation Codec for Speech Language Models](https://arxiv.org/abs/2501.00018) |                                                              |        |
| [EmoReg: Directional Latent Vector Modeling for Emotional Intensity Regularization in Diffusion-based Voice Conversion](https://arxiv.org/abs/2412.20359) |                                                              |        |
| [BSDB-Net: Band-Split Dual-Branch Network with Selective State Spaces Mechanism for Monaural Speech Enhancement](https://arxiv.org/abs/2412.19099) |                                                              |        |
| [Enhancing Audiovisual Speech Recognition through Bifocal Preference Optimization](https://arxiv.org/abs/2412.19005) |                                                              |        |
| [MathSpeech: Leveraging Small LMs for Accurate Conversion in Mathematical Speech-to-Formula](https://arxiv.org/abs/2412.15655) |                                                              |        |
| [Speech Watermarking with Discrete Intermediate Representations](https://arxiv.org/abs/2412.13917) |                                                              |        |
| [ProsodyFM: Unsupervised Phrasing and Intonation Control for Intelligible Speech Synthesis](https://arxiv.org/abs/2412.11795) |                                                              |        |
| [Complex-Cycle-Consistent Diffusion Model for Monaural Speech Enhancement](https://arxiv.org/abs/2412.08856) |                                                              |        |
| [StableVC: Style Controllable Zero-Shot Voice Conversion with Conditional Flow Matching](https://arxiv.org/abs/2412.04724) |                                                              |        |
| [DEEPTalk: Dynamic Emotion Embedding for Probabilistic Speech-Driven 3D Face Animation](https://arxiv.org/abs/2408.06010) |                                                              |        |

### Audio

| Paper                                                        | Authorlist                                                   | Status |
| ------------------------------------------------------------ | ------------------------------------------------------------ | ------ |
| [Codec does matter: Exploring the semantic shortcoming of codec for audio language model](https://ojs.aaai.org/index.php/AAAI/article/view/34761) | Zhen Ye, Peiwen Sun, Jiahe Lei, Hongzhan Lin, Xu Tan, Zheqi Dai, Qiuqiang Kong, Jianyi Chen, Jiahao Pan, Qifeng Liu, Yike Guo, Wei Xue |        |
| [TechSinger: Technique Controllable Multilingual Singing Voice Synthesis via Flow Matching](https://arxiv.org/abs/2502.12572) |                                                              |        |
| [MIDI-GPT: A Controllable Generative Model for Computer-Assisted Multitrack Music Composition](https://arxiv.org/abs/2501.17011) |                                                              |        |
| [GVMGen: A General Video-to-Music Generation Model with Hierarchical Attentions](https://arxiv.org/abs/2501.09972) |                                                              |        |
| [Detecting Music Performance Errors with Transformers](https://arxiv.org/abs/2501.02030) |                                                              |        |
| [SoundBrush: Sound as a Brush for Visual Scene Editing](https://arxiv.org/abs/2501.00645) |                                                              |        |
| [Tri-Ergon: Fine-grained Video-to-Audio Generation with Multi-modal Conditions and LUFS Control](https://arxiv.org/abs/2412.20378) |                                                              |        |
| [SongGLM: Lyric-to-Melody Generation with 2D Alignment Encoding and Multi-Task Pre-Training](https://arxiv.org/abs/2412.18107) |                                                              |        |
| [JoVALE: Detecting Human Actions in Video Using Audiovisual and Language Contexts](https://arxiv.org/abs/2412.13708) |                                                              |        |
| [Query-centric Audio-Visual Cognition Network for Moment Retrieval, Segmentation and Step-Captioning](https://arxiv.org/abs/2412.13543) |                                                              |        |
| [Dense Audio-Visual Event Localization under Cross-Modal Consistency and Multi-Temporal Granularity Collaboration](https://arxiv.org/abs/2412.12628) |                                                              |        |
| [DLF: Disentangled-Language-Focused Multimodal Sentiment Analysis](https://arxiv.org/abs/2412.12225) |                                                              |        |
| [Region-Based Optimization in Continual Learning for Audio Deepfake Detection](https://arxiv.org/abs/2412.11551) |                                                              |        |
| [Enriching Multimodal Sentiment Analysis through Textual Emotional Descriptions of Visual-Audio Content](https://arxiv.org/abs/2412.10460) |                                                              |        |
| [GoHD: Gaze-oriented and Highly Disentangled Portrait Animation with Rhythmic Poses and Realistic Expression](https://arxiv.org/abs/2412.09296) |                                                              |        |
| [PointTalk: Audio-Driven Dynamic Lip Point Cloud for 3D Gaussian-based Talking Head Synthesis](https://arxiv.org/abs/2412.08504) |                                                              |        |
| [Unleashing the Temporal-Spatial Reasoning Capacity of GPT for Training-Free Audio and Language Referenced Video Object Segmentation](https://arxiv.org/abs/2408.15876) |                                                              |        |
| [JEN-1 Composer: A Unified Framework for High-Fidelity Multi-Track Music Generation](https://arxiv.org/abs/2310.19180) |                                                              |        |
| [SongEditor: Adapting Zero-Shot Song Generation Language Model as a Multi-Task Editor](https://arxiv.org/abs/2412.13786) |                                                              |        |
| [CSSinger: End-to-End Chunkwise Streaming Singing Voice Synthesis System Based on Conditional Variational Autoencoder](https://arxiv.org/abs/2412.08918) |                                                              |        |
| [Read, Watch and Scream! Sound Generation from Text and Video](https://arxiv.org/abs/2407.05551) |                                                              |        |
| [Mental-Perceiver: Audio-Textual Multi-Modal Learning for Estimating Mental Disorders](https://arxiv.org/abs/2408.12088) |                                                              |        |

## IJCAI'24

useful link: https://ijcai24.org/main-track-accepted-papers/index.html

The number of this conference (speech&audio) is small.

### Speech

| Paper                                                        | Authorlist                                                   | Status |
| ------------------------------------------------------------ | ------------------------------------------------------------ | ------ |
| **Separate in the Speech Chain: Cross-Modal Conditional Audio-Visual Target Speech Extraction** | *Zhaoxi Mu, Xinyu Yang*                                      |        |
| **Bridge to Non-Barrier Communication: Gloss-Prompted Fine-Grained Cued Speech Gesture Generation with Diffusion Model** | *Wentao Lei, Li Liu, Jun Wang*                               |        |
| **Two-stage Semi-supervised Speaker Recognition with Gated Label Learning** | *Xingmei Wang, Jiaxiang Meng, Kong Aik Lee, Boquan Li, Jinghan Liu* |        |
| **Discriminative Feature Decoupling Enhancement for Speech Forgery Detection** | *Yijun Bei, Xing Zhou, Erteng Liu, Yang Gao, Sen Lin, Kewei Gao, Zunlei Feng* |        |
| **Innovative Directional Encoding in Speech Processing: Leveraging Spherical Harmonics Injection for Multi-Channel Speech Enhancement** | *Jiahui Pan, Pengjie Shen, Hui Zhang, Xueliang Zhang*        |        |
| **Contextualized Speech Recognition: Rethinking Second-Pass Rescoring with Generative Large Language Models** | *Yixuan Tang, Anthony K. H. Tung*                            |        |
| **Speech-Forensics: Towards Comprehensive Synthetic Speech Dataset Establishment and Analysis** | *Zhoulin Ji, Chenhao Lin, Hang Wang, Chao Shen*              |        |
| **Decoupling Breaks Data Barriers: A Decoupled Pre-training Framework for Multi-intent Spoken Language Understanding** | *Libo Qin, Qiguang Chen, Jingxuan Zhou, Qinzheng Li, Chunlin Lu, Wanxiang Che* |        |
| **Recent Advances in End-to-End Simultaneous Speech Translation** | *Xiaoqian Liu, Guoqiang Hu, Yangfan Du, Erfeng He, YingFeng Luo, Chen Xu, Tong Xiao, Jingbo Zhu* | Survey |

### Audio

| Paper                                                        | Authorlist                                                   | Status |
| ------------------------------------------------------------ | ------------------------------------------------------------ | ------ |
| **EAT: Self-Supervised Pre-Training with Efficient Audio Transformer** | *Wenxi Chen, Yuzhe Liang, Ziyang Ma, Zhisheng Zheng, Xie Chen* |        |
| **Generating More Audios for End-to-End Spoken Language Understanding** | *Xuxin Cheng, Yuexian Zou*                                   |        |
| **BATON: Aligning Text-to-Audio Model Using Human Preference Feedback** | *Huan Liao, Haonan Han, Kai Yang, Tianjiao Du, Rui Yang, Qinmei Xu, Zunnan Xu, Jingquan Liu, Jiasheng Lu, Xiu Li* |        |
| **HyDiscGAN: A Hybrid Distributed cGAN for Audio-Visual Privacy Preservation in Multimodal Sentiment Analysis** | *Zhuojia Wu, Qi Zhang, Duoqian Miao, Kun Yi, Wei Fan, Liang Hu* |        |
| **InstructME: An Instruction Guided Music Edit Framework with Latent Diffusion Models** | *Bing Han, Junyu Dai, Weituo Hao, Xinyan He, Dong Guo, Jitong Chen, Yuxuan Wang, Yanmin Qian, Xuchen Song* |        |

## ICML'25

### Speech

| Paper                                                        | Authorlist | Status |
| ------------------------------------------------------------ | ---------- | ------ |
| [MoHAVE: Mixture of Hierarchical Audio-Visual Experts for Robust Speech Recognition](https://icml.cc/virtual/2025/poster/44834) |            |        |
| [The Brain's Bitter Lesson: Scaling Speech Decoding With Self-Supervised Learning](https://icml.cc/virtual/2025/poster/44019) |            |        |
| [DMOSpeech: Direct Metric Optimization via Distilled Diffusion Model in Zero-Shot Speech Synthesis](https://icml.cc/virtual/2025/poster/44048) |            |        |
| [Do Not Mimic My Voice : Speaker Identity Unlearning for Zero-Shot Text-to-Speech](https://icml.cc/virtual/2025/poster/46647) |            |        |
| [BinauralFlow: A Causal and Streamable Approach for High-Quality Binaural Speech Synthesis with Flow Matching Models](https://icml.cc/virtual/2025/poster/46249) |            |        |
| [Emotional Face-to-Speech](https://icml.cc/virtual/2025/poster/45920) |            |        |
| [DiTAR: Diffusion Transformer Autoregressive Modeling for Speech Generation](https://icml.cc/virtual/2025/poster/46258) |            |        |
| [Unsupervised Blind Speech Separation with a Diffusion Prior](https://icml.cc/virtual/2025/poster/46648) |            |        |
| [Sortformer: A Novel Approach for Permutation-Resolved Speaker Supervision in Speech-to-Text Systems](https://icml.cc/virtual/2025/poster/46140) |            |        |
| [High-Fidelity Simultaneous Speech-To-Speech Translation](https://icml.cc/virtual/2025/poster/44512) |            |        |
| [Improving Conversational Capabilities of Speech Language Models via Generative Dual-channel Spoken Dialogue Learning](https://icml.cc/virtual/2025/poster/46439) |            |        |
| [Freeze-Omni: A Smart and Low Latency Speech-to-speech Dialogue Model with Frozen LLM](https://icml.cc/virtual/2025/poster/43854) |            |        |
| [OWLS: Scaling Laws for Multilingual Speech Recognition and Translation Models](https://icml.cc/virtual/2025/poster/43563) |            |        |
| [Long-Form Speech Generation with Spoken Language Models](https://icml.cc/virtual/2025/poster/46499) |            |        |
| [Aligning Spoken Dialogue Models from User Interactions](https://icml.cc/virtual/2025/poster/44228) |            | spoken |
| [A Variational Framework for Improving Naturalness in Generative Spoken Language Models](https://icml.cc/virtual/2025/poster/45785) |            |        |
| [De-AntiFake: Rethinking the Protective Perturbations Against Voice Cloning Attacks](https://icml.cc/virtual/2025/poster/45768) |            |        |

### Audio

| Paper                                                        | Authorlist | Status |
| ------------------------------------------------------------ | ---------- | ------ |
| [XAttnMark: Learning Robust Audio Watermarking with Cross-Attention](https://icml.cc/virtual/2025/poster/43452) |            |        |
| [ETTA: Elucidating the Design Space of Text-to-Audio Models](https://icml.cc/virtual/2025/poster/44876) |            |        |
| [Audio Flamingo 2: An Audio-Language Model with Long-Audio Understanding and Expert Reasoning Abilities](https://icml.cc/virtual/2025/poster/43577) |            |        |
| [Sounding that Object: Interactive Object-Aware Image to Audio Generation](https://icml.cc/virtual/2025/poster/46382) |            |        |
| [ALMTokenizer: A Low-bitrate and Semantic-rich Audio Codec Tokenizer for Audio Language Modeling](https://icml.cc/virtual/2025/poster/45316) |            |        |
| [Generative Audio Language Modeling with Continuous-valued Tokens and Masked Next-Token Prediction](https://icml.cc/virtual/2025/poster/45195) |            |        |
| [Supervised Contrastive Learning from Weakly-Labeled Audio Segments for Musical Version Matching](https://icml.cc/virtual/2025/poster/46594) |            |        |
| [FLAM: Frame-Wise Language-Audio Modeling](https://icml.cc/virtual/2025/poster/46310) |            |        |
| [MATS: An Audio Language Model under Text-only Supervision](https://icml.cc/virtual/2025/poster/44538) |            |        |
| [AGAV-Rater: Adapting Large Multimodal Model for AI-Generated Audio-Visual Quality Assessment](https://icml.cc/virtual/2025/poster/43704) |            |        |
| [AudioSpace: Generating Spatial Audio from 360-Degree Video](https://icml.cc/virtual/2025/poster/43952) |            |        |
| [IMPACT: Iterative Mask-based Parallel Decoding for Text-to-Audio Generation with Diffusion Modeling](https://icml.cc/virtual/2025/poster/46189) |            |        |
| [video-SALMONN-o1: Reasoning-enhanced Audio-visual Large Language Model](https://icml.cc/virtual/2025/poster/43555) |            |        |
| [Efficient Fine-Grained Guidance for Diffusion-Based Symbolic Music Generation](https://icml.cc/virtual/2025/poster/44043) |            | music  |
| [MuseControlLite: Multifunctional Music Generation with Lightweight Conditioners](https://icml.cc/virtual/2025/poster/45072) |            |        |

## Useful Survey & Awesome Link

+ Expressive TTS: https://github.com/01Zhangbw/Awesome-Expressive-speech-synthesis
+ Disordered Speech: https://github.com/01Zhangbw/Awesome-Disordered-Speech

+ Neural Codec & Speech Language Models: https://github.com/LqNoob/Neural-Codec-and-Speech-Language-Models
+ Controllable TTS: https://github.com/imxtx/awesome-controllabe-speech-synthesis
+ Large Audio Model: https://github.com/EmulationAI/awesome-large-audio-models
+ Codec-SuperB: https://github.com/voidful/Codec-SUPERB
+ Next Token Prediction: https://github.com/LMM101/Awesome-Multimodal-Next-Token-Prediction
+ Paper daily: https://github.com/halsay/ASR-TTS-paper-daily
+ Audio LLM: https://github.com/AudioLLMs/Awesome-Audio-LLM
+ Speech Trident: https://github.com/ga642381/speech-trident
+ Speech Pretrained: https://github.com/ddlBoJack/Awesome-Speech-Pretraining
+ TTS: https://github.com/wenet-e2e/speech-synthesis-paper
+ Speech Language model: https://github.com/ddlBoJack/Awesome-Speech-Language-Model
+ [Amphion](https://github.com/open-mmlab/Amphion)
+ InterSpeech23-24: https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers
+ ICASSP23-24: https://github.com/DmitryRyumin/ICASSP-2023-24-Papers

1. Amphion v0.2 technical report
   https://arxiv.org/abs/2501.15442

2. Emilia-LargeÔºöÊõ¥Â§ßÊùØÔºåÊõ¥Â§öÂÆûÈ™åÁªìÊûúÂèäÁªÜËäÇ
   https://arxiv.org/abs/2501.15907

3. AnyEnhanceÔºöËØ≠Èü≥Â¢ûÂº∫„ÄÅÊ≠åÂ£∞Â¢ûÂº∫„ÄÅËØ¥ËØù‰∫∫ÊèêÂèñÁ≠âÁ≠â‰ªªÂä°ÔºåAnyEnhance‰∏Ä‰∏™Ê®°ÂûãÂÖ®ÊêûÂÆö
   https://arxiv.org/abs/2501.15417

## Citation

If you find this repository helpful, please consider citing:

```
@misc{Zhang2025SpeechAudio,
  title = {Speech-and-audio-papers-Top-Conference},
  author = {Bowen Zhang},
  year = {2025},
  howpublished = {\url{https://github.com/01Zhangbw/Speech-and-audio-papers-Top-Conference}},
}
```

## License

This repository is released under the [MIT license](https://github.com/01Zhangbw/Speech-and-audio-papers-Top-Conference/blob/main/LICENSE).
